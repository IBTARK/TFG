{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c2d0ec-b1c2-4e74-8c57-562b03aff8f1",
   "metadata": {},
   "source": [
    "# Ampliación de datos\n",
    "\n",
    "En este notebook se va a aplicar la técnica de ampliación de datos a un conjunto de reseñas de Google Maps separadas en dos ficheros: uno con las reseñas que se van a considerar válidas y el otro con las inválidas. Cada línea es una reseña nueva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0485a5-5543-499d-a2a6-ce3ab7333f3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54d4a66-799a-460d-b32e-b71b3755cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ibon/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ibon/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deep_translator import (GoogleTranslator, MyMemoryTranslator)\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20fd15-c646-4f3d-857f-3b2d8822f88e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Direcorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c311128e-92e1-4101-b796-8b8165fe12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "validReviewsPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidReviewsPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ac5b7-6508-4ea6-bca1-ffe46883ecc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pandas\n",
    "Se van a pasar los datos a dataframes: uno con las valoraciones validas y otro con las negativas. Cada fila del dataframe será una reseña"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66162710-f9ad-43e4-a0bf-1f5a92a065a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFromTxtToDF(source):\n",
    "    with open(source, 'r', encoding=\"utf-8\") as file:\n",
    "        #Generate a list with all the reviews\n",
    "        targetList = [line.strip() for line in file]\n",
    "\n",
    "    targetDF = pd.DataFrame(targetList, columns=['Text'])\n",
    "    return targetDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5a9830-a956-4dd6-9b78-26f4866a408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file with the valid reviews\n",
    "validReviewsDF = importFromTxtToDF(validReviewsPath)\n",
    "#Read the file with the invalid reviews\n",
    "invalidReviewsDF = importFromTxtToDF(invalidReviewsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca07cf-8f96-40c5-886e-9a26f7524bfe",
   "metadata": {},
   "source": [
    "Se muestran las primeras reseñas válidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1cdd36-9728-4962-a4bd-b6bf4731e01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bien\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  \"Tiene fácil acceso para las personas con movi...\n",
       "1                        \"Espero que hayan mejorais\"\n",
       "2  \"La estación es antigua, aparte de tener una s...\n",
       "3                                             \"Bien\"\n",
       "4                                    \"Bonito comodo\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validReviewsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57d6e4-e380-4a66-a893-b032b7257254",
   "metadata": {},
   "source": [
    "Se muestran las primeras reseñas inválidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6074bca2-03f7-4503-8dcf-01069a61d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"…\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  \"He vivido 35 años en el barrio y reconozco qu...\n",
       "1       \"localización con muchos bares interesantes\"\n",
       "2                                                \"…\"\n",
       "3                                \"Muy rica comida..\"\n",
       "4                               \"Estación del.metro\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalidReviewsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76053968-2837-4890-9018-53164468d5e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Medidas de similitud\n",
    "Para poder comparar frases y seleccionar las mejores para generar los mejores datasets se van a desarrollar las siguientes medidas de similitud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cabc1a-a9a7-4338-b716-670faa6759f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Similitud Semántica\n",
    "\n",
    "A continuación se va a diseñar una función para calcular la similitud semántica entre pares de oraciones. Es decir, se van a calcular los embeddings de oraciones de cada par de frases y se va a usar una métrica de similitud para ver como de parecido es el significado de ambas frases.\n",
    "\n",
    "Se va a usar una versión de SBERT, llamada MiniLM (Minimal Lenguaje Model), que utiliza una variante más pequeña. Se usa MiniLM de seis capas (L6), que logra una precisón buena con menos recursos.\n",
    "\n",
    "Este modelo fue entrenado usando un dataset que incluye datos en varios idiomas, entre ellos el español. Consecuentemente, no hay problema al introducir frases en castellano. Es cierto, que obtiene mejores resultados para frases en inglés, ya que se entreno con más datos en este idioma.\n",
    "\n",
    "MiniLM es un modelo específicamente entrenado para mapear frases y parrafos a un espacio vectorial de 384 dimensiones. Es decir, este modelo permite obtener un embedding de una frase directamente. Usando otros modelos esta tarea no es posible de forma directa, ya que devuelven un embedding para cada palabra del texto.\n",
    "\n",
    "El método de similitud que se va a usar es la similitud del coseno, por lo que los valores más cercanos a uno indicarán una mayor similitud entre las frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f362a20-b0b3-47a0-a3c5-bd3d880b100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Given two texts and a model, the semantic similarity of the texts is returned\n",
    "def getSemanticSimilarity(text1, text2, model):\n",
    "    #Get the embeddings of the senteces\n",
    "    embedding1 = model.encode(text1)\n",
    "    embedding2 = model.encode(text2)\n",
    "\n",
    "    #Get the cosine similarity of the senteces\n",
    "    similarity = cosine_similarity([embedding1], [embedding2])\n",
    "\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfd655-adc8-4e17-b7e6-7317ee6ac73c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Similitud Léxica\n",
    "Se va a diseñar una función para calcular la similitud léxica entre pares de oraciones. La similitud léxica mide el grado de coincidencia de palabras o términos entre dos frases o textos, sin tener en cuenta el significado subyacente.\n",
    "\n",
    "Hay varias formas de realizar este cálculo: similitud del coseno basada en frecuencia de palabras, coeficiente de Jaccard,coeficiente de Dice ...\n",
    "\n",
    "En este caso, se cree que la mejor opción es usar el coeficiente de Jaccard ya que calcula la similitud en función de la proporción de palabras comunes sobre el total de palabras únicas. Consecuentemente, esto nos permitirá detectar frases con menos coincidencias exactas en palabras.\n",
    "\n",
    "Cuanto más cercano a uno sea el coeficiente de Jaccard más similares léxicamente serán las frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9351fcd7-4bd3-44d4-87b5-f80332bb6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "#Clean up the text removing punctuation, accent marks and convertin everything to lowercase\n",
    "def cleanText(text):\n",
    "    text = unicodedata.normalize('NFKD', text.lower()).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca07c96b-cfa3-4497-af79-07918de06454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpanishStopWords():\n",
    "    determinantes = {\"el\", \"la\", \"los\", \"las\", \"un\", \"una\", \"unos\", \"unas\", \"este\", \"esta\", \"estos\", \"estas\",\n",
    "                 \"ese\", \"esa\", \"esos\", \"esas\", \"aquel\", \"aquella\", \"aquellos\", \"aquellas\", \"mi\", \"mis\",\n",
    "                 \"tu\", \"tus\", \"su\", \"sus\", \"nuestro\", \"nuestra\", \"nuestros\", \"nuestras\", \"vuestro\", \n",
    "                 \"vuestra\", \"vuestros\", \"vuestras\", \"primer\", \"primero\", \"primera\", \"segundo\", \"segunda\"}\n",
    "\n",
    "    preposiciones = {\"a\", \"ante\", \"bajo\", \"cabe\", \"con\", \"contra\", \"de\", \"desde\", \"durante\", \"en\", \"entre\", \n",
    "                 \"hacia\", \"hasta\", \"mediante\", \"para\", \"por\", \"según\", \"sin\", \"sobre\", \"tras\", \"versus\", \"vía\"}\n",
    "\n",
    "    conjunciones = {\"y\", \"e\", \"ni\", \"o\", \"u\", \"pero\", \"sino\", \"sino que\", \"mas\", \"aunque\", \"que\", \"porque\", \n",
    "                \"como\", \"cuando\", \"donde\", \"mientras\", \"para que\", \"a fin de que\", \"puesto que\", \"ya que\", \n",
    "                \"si\", \"siempre que\"}\n",
    "    pronombres = {\n",
    "        # Pronombres personales\n",
    "        \"yo\", \"tú\", \"vos\", \"él\", \"ella\", \"nosotros\", \"nosotras\", \n",
    "        \"vosotros\", \"vosotras\", \"ellos\", \"ellas\", \"usted\", \"ustedes\",\n",
    "        \"me\", \"te\", \"lo\", \"la\", \"nos\", \"os\", \"los\", \"las\", \"le\", \"les\", \"se\",\n",
    "    \n",
    "        # Pronombres posesivos\n",
    "        \"mío\", \"mía\", \"míos\", \"mías\", \n",
    "        \"tuyo\", \"tuya\", \"tuyos\", \"tuyas\", \n",
    "        \"suyo\", \"suya\", \"suyos\", \"suyas\", \n",
    "        \"nuestro\", \"nuestra\", \"nuestros\", \"nuestras\", \n",
    "        \"vuestro\", \"vuestra\", \"vuestros\", \"vuestras\",\n",
    "    \n",
    "        # Pronombres demostrativos\n",
    "        \"este\", \"esta\", \"estos\", \"estas\", \n",
    "        \"ese\", \"esa\", \"esos\", \"esas\", \n",
    "        \"aquel\", \"aquella\", \"aquellos\", \"aquellas\",\n",
    "    \n",
    "        # Pronombres relativos\n",
    "        \"que\", \"cual\", \"cuales\", \"quien\", \"quienes\", \n",
    "        \"cuyo\", \"cuya\", \"cuyos\", \"cuyas\", \"donde\",\n",
    "    \n",
    "        # Pronombres interrogativos y exclamativos\n",
    "        \"qué\", \"quién\", \"quiénes\", \"cuál\", \"cuáles\", \n",
    "        \"cuánto\", \"cuánta\", \"cuántos\", \"cuántas\", \n",
    "        \"dónde\", \"cómo\", \"cuándo\",\n",
    "    \n",
    "        # Pronombres indefinidos\n",
    "        \"alguien\", \"algo\", \"nadie\", \"nada\", \"cualquiera\", \n",
    "        \"todos\", \"todas\", \"varios\", \"varias\", \"muchos\", \n",
    "        \"muchas\", \"pocos\", \"pocas\", \"alguno\", \"alguna\", \n",
    "        \"algunos\", \"algunas\", \"ninguno\", \"ninguna\", \n",
    "        \"uno\", \"una\", \"unos\", \"unas\", \"demás\"\n",
    "    }\n",
    "\n",
    "    #Combine all the words in one set\n",
    "    spanishStopWords = determinantes | preposiciones | conjunciones | pronombres\n",
    "\n",
    "    return spanishStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb9a832-8b99-4a74-a0f4-9fd6fabd3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revomeSpanishStopWords(text):\n",
    "    spanishStopWords = getSpanishStopWords()\n",
    "\n",
    "    textWithoutStopWords = [word for word in text.split() if word.lower() not in spanishStopWords]\n",
    "\n",
    "    return \" \".join(textWithoutStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c35a79c-e4e7-4854-9b4f-67b925b37928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard similarity\n",
    "def jaccardSimilarity(text1, text2):\n",
    "    #Get the set of words of each text\n",
    "    wordsInText1 = set(revomeSpanishStopWords(cleanText(text1)).split())\n",
    "    wordsInText2 = set(revomeSpanishStopWords(cleanText(text2)).split())\n",
    "\n",
    "    intersection = len(wordsInText1.intersection(wordsInText2)) \n",
    "    union = len(wordsInText1.union(wordsInText2))\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0\n",
    "\n",
    "    #intersection / union\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c7a577-4e14-4d46-9954-cf96575bf14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given two texts, the Jaccard similarity of those texts is returned\n",
    "def getLexicalSimilarity(text1, text2):\n",
    "    return jaccardSimilarity(text1, text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b81dbd-a09d-4a75-9fd0-ae00c1d45366",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Retrotraducción\n",
    "\n",
    "El primer método de ampliación de datos que se va a usar va a ser la retrotraducción. Consiste en traducir el texto a un idioma distinto y luego volverlo a traducir al idioma original. \n",
    "\n",
    "Este proceso puede genera texto con el mismo significado que el original pero distintas palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d137f41-d490-4723-b33d-252f91ea8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackTranslation(translatorsList, reviewsDF, targetPath):\n",
    "    #Generate a data list to store the text that has to be translated\n",
    "    notTranslatedList = reviewsDF['Text'].tolist()\n",
    "\n",
    "    #Translate the text as many times as needed\n",
    "    for translator in translatorsList:\n",
    "        #Generate a data frame to store the text that has been translated\n",
    "        translatedList = []\n",
    "        for elem in notTranslatedList:\n",
    "            #Translate all the reviews\n",
    "            try:\n",
    "                translation = translator.translate(elem)\n",
    "            except Exception as e: #If the translation fails \"\" is written\n",
    "                translation = '\"\"'\n",
    "            #If an error ocurred translate it to a \"\"\n",
    "            if translation == None:\n",
    "                translation = '\"\"'\n",
    "                \n",
    "            #Save the translations in the corresponding list \n",
    "            translatedList.append(translation)\n",
    "\n",
    "            #Wait 0.2 seconds not to collapse the server\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        #Prepare to translate again if needed\n",
    "        notTranslatedList = copy.deepcopy(translatedList) \n",
    "       \n",
    "    #Open the file in which the translations are strored\n",
    "    translationFile = open(targetPath, 'w', encoding=\"utf-8\")\n",
    "    #write all the translations\n",
    "    for elem in translatedList:\n",
    "        translationFile.write(elem + \"\\n\")\n",
    "    #Close the file\n",
    "    translationFile.close()\n",
    "    \n",
    "    return pd.DataFrame(translatedList, columns=['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3dd031-96ec-4ac7-9c93-c7ea4cff8fce",
   "metadata": {},
   "source": [
    "### Google Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28785755-a28b-4caa-8c37-9f86cabb95e1",
   "metadata": {},
   "source": [
    "Primero se va a traducir del castellano al ingles y luego del inglés al castellano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c9d79f-598c-423d-9092-05b4ed9e0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = '1. Back Translation\\\\1. Google Translator\\\\ValidReviewsTranslationsEsEnEnEs.txt'\n",
    "invalidPath = '1. Back Translation\\\\1. Google Translator\\\\InvalidReviewsTranslationsEsEnEnEs.txt'\n",
    "\n",
    "firstTranslator = GoogleTranslator(source = 'es', target = 'en')\n",
    "secondTranslator = GoogleTranslator(source='en', target='es')\n",
    "\n",
    "translatorList = [firstTranslator, secondTranslator]\n",
    "\n",
    "validSpanishReviewsGoogleEsEnEnEsDF = BackTranslation(translatorList, validReviewsDF, validPath)\n",
    "invalidSpanishReviewsGoogleEsEnEnESDF = BackTranslation(translatorList, invalidReviewsDF, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e9e09-275c-4b2e-bc8a-0824a8e809fc",
   "metadata": {},
   "source": [
    "A continuación se va a traducir del castellano al japonés y del japonés al castellano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "587bc968-c0b2-437c-8f89-e3bd1e30ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = '1. Back Translation\\\\1. Google Translator\\\\ValidReviewsTranslationsEsJaJaEs.txt'\n",
    "invalidPath = '1. Back Translation\\\\1. Google Translator\\\\InvalidReviewsTranslationsEsJaJaEs.txt'\n",
    "\n",
    "firstTranslator = GoogleTranslator(source = 'es', target = 'ja')\n",
    "secondTranslator = GoogleTranslator(source='ja', target='es')\n",
    "\n",
    "translatorList = [firstTranslator, secondTranslator]\n",
    "\n",
    "validSpanishReviewsGoogleEsJaJaEsDF = BackTranslation(translatorList, validReviewsDF, validPath)\n",
    "invalidSpanishReviewsGoogleEsJaJaEsDF = BackTranslation(translatorList, invalidReviewsDF, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9adc18-5942-4324-9ce4-52d941f1ef0a",
   "metadata": {},
   "source": [
    "Por último se va a implementar una cadena de traducciones más larga: castellano a frances, frances a japones, japones a ruso y ruso a catellano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f0b7f2-efd6-4329-8d88-07b12d32e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = '1. Back Translation\\\\1. Google Translator\\\\ValidReviewsTranslationsEsFrFrJaJaRuRuEs.txt'\n",
    "invalidPath = '1. Back Translation\\\\1. Google Translator\\\\InvalidReviewsTranslationsEsFrFrJaJaRuRuEs.txt'\n",
    "\n",
    "firstTranslator = GoogleTranslator(source = 'es', target = 'fr')\n",
    "secondTranslator = GoogleTranslator(source='fr', target='ja')\n",
    "thirdTranslator = GoogleTranslator(source='ja', target='ru')\n",
    "fourthTranslator = GoogleTranslator(source='ru', target='es')\n",
    "\n",
    "translatorList = [firstTranslator, secondTranslator, thirdTranslator, fourthTranslator]\n",
    "\n",
    "validSpanishReviewsGoogleEsFrFrJaJaRuRuEsDF = BackTranslation(translatorList, validReviewsDF, validPath)\n",
    "invalidSpanishReviewsGoogleEsFrFrJaJaRuRuEsDF = BackTranslation(translatorList, invalidReviewsDF, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a245504-b6e0-47a3-9276-2498b5f147dd",
   "metadata": {},
   "source": [
    "### MyMemory Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79951b8d-efd6-414f-a644-d44895f204c3",
   "metadata": {},
   "source": [
    "Se van a realizar las mismas traducciones pero usando otro traductor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42669f5-986e-457f-943e-354d638a8da5",
   "metadata": {},
   "source": [
    "Castellano -> Inglés -> Castellano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33609a91-efa8-4d7c-9ab0-cdd9238b1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = '1. Back Translation\\\\2. MyMemory Translator\\\\ValidReviewsTranslationsEsEnEnEs.txt'\n",
    "invalidPath = '1. Back Translation\\\\2. MyMemory Translator\\\\InvalidReviewsTranslationsEsEnEnEs.txt'\n",
    "\n",
    "firstTranslator = MyMemoryTranslator(source = 'spanish', target = 'english')\n",
    "secondTranslator = MyMemoryTranslator(source='english', target='spanish')\n",
    "\n",
    "translatorList = [firstTranslator, secondTranslator]\n",
    "\n",
    "validSpanishReviewsMyMemoryEsEnEnEsDF = BackTranslation(translatorList, validReviewsDF, validPath)\n",
    "invalidSpanishReviewsMyMemoryEsEnEnEsDF = BackTranslation(translatorList, invalidReviewsDF, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90792d9d-d9df-43cf-96e1-4b8793450c79",
   "metadata": {},
   "source": [
    "Castellano -> Japonés -> Castellano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a207d69a-a95f-401b-ad78-0ca9c32cffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = '1. Back Translation\\\\2. MyMemory Translator\\\\ValidReviewsTranslationsEsJaJaEs.txt'\n",
    "invalidPath = '1. Back Translation\\\\2. MyMemory Translator\\\\InvalidReviewsTranslationsEsJaJaEs.txt'\n",
    "\n",
    "firstTranslator = MyMemoryTranslator(source = 'spanish', target = 'japanese')\n",
    "secondTranslator = MyMemoryTranslator(source='japanese', target='spanish')\n",
    "\n",
    "translatorList = [firstTranslator, secondTranslator]\n",
    "\n",
    "validSpanishReviewsMyMemoryEsJaJaEsDF = BackTranslation(translatorList, validReviewsDF, validPath)\n",
    "invalidSpanishReviewsMyMemoryEsJaJaEsDF = BackTranslation(translatorList, invalidReviewsDF, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513691e0-fab9-4d6a-9ee5-0fb7716dc9ef",
   "metadata": {},
   "source": [
    "Castellano -> Francés -> Japonés -> Ruso -> Castellano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0f68de-f676-421f-ba70-d85af504a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = '1. Back Translation\\\\2. MyMemory Translator\\\\ValidReviewsTranslationsEsFrFrJaJaRuRuEs.txt'\n",
    "invalidPath = '1. Back Translation\\\\2. MyMemory Translator\\\\InvalidReviewsTranslationsEsFrFrJaJaRuRuEs.txt'\n",
    "\n",
    "firstTranslator = MyMemoryTranslator(source = 'spanish', target = 'french')\n",
    "secondTranslator = MyMemoryTranslator(source='french', target='japanese')\n",
    "thirdTranslator = MyMemoryTranslator(source='japanese', target='russian')\n",
    "fourthTranslator = MyMemoryTranslator(source='russian', target='spanish')\n",
    "\n",
    "translatorList = [firstTranslator, secondTranslator, thirdTranslator, fourthTranslator]\n",
    "\n",
    "validSpanishReviewsMyMemoryEsFrFrJaJaRuRuEsDF = BackTranslation(translatorList, validReviewsDF, validPath)\n",
    "invalidSpanishReviewsMyMemoryEsFrFrJaJaRuRuEsDF = BackTranslation(translatorList, invalidReviewsDF, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac7f30-7ad4-4660-8633-a0b4f2b725f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Análisis de la retrotraducción y selección de los datos\n",
    "\n",
    "Dado que el código correspondiente a la traducción llevó largo rato y se dejo a la noche ejecutando, se vuelven a importar los datos a dataframes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d80455-27fb-4758-90ca-a6b187e3649b",
   "metadata": {},
   "source": [
    "#### MyMemory genera errores en la traducción debido a problemas de conexión con el servidor. Consecuentemente, se procede a anilizar únicamente los datos generados por el traductor de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "676fead3-89d2-41ca-9d2c-75df79bb16bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFromTxtToList(source):\n",
    "    with open(source, 'r', encoding=\"utf-8\") as file:\n",
    "        #Generate a list with all the reviews\n",
    "        targetList = [line.strip() for line in file]\n",
    "    return targetList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319d605-4149-4b84-b1ce-3f4124398124",
   "metadata": {},
   "source": [
    "Frases originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6bd3ee6-89fa-4cf7-b50f-d1e49d2364e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validPath)\n",
    "invalidOriginal = importFromTxtToList(invalidPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738bf88b-1fc7-4cad-a2ff-9464486bf40d",
   "metadata": {},
   "source": [
    "Se importan las frases traducidas de: Castellano -> Inglés -> Castellano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa962044-f7c9-44e0-b81e-a3aed6b90550",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = '1. Back Translation/1. Google Translator/ValidReviewsTranslationsEsEnEnEs.txt'\n",
    "invalidPath = '1. Back Translation/1. Google Translator/InvalidReviewsTranslationsEsEnEnEs.txt'\n",
    "\n",
    "validEsEnEnEsTraductionList = importFromTxtToList(validPath)\n",
    "invalidEsEnEnEsTraductionList = importFromTxtToList(invalidPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aba3e7-7b3e-4edd-b6fa-6614cdb5b1f0",
   "metadata": {},
   "source": [
    "Castellano -> Japonés -> Castellano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b4a68b0-2a8a-4037-946e-e9571106c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = '1. Back Translation/1. Google Translator/ValidReviewsTranslationsEsJaJaEs.txt'\n",
    "invalidPath = '1. Back Translation/1. Google Translator/InvalidReviewsTranslationsEsJaJaEs.txt'\n",
    "\n",
    "validEsJaJaEsTraductionList = importFromTxtToList(validPath)\n",
    "invalidEsJaJaEsTraductionList = importFromTxtToList(invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e926d10c-9623-4b7d-bf42-6194e822d03b",
   "metadata": {},
   "source": [
    "Castellano -> Francés -> Japonés -> Ruso -> Castellano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f757675-d52d-462c-8a24-7711a338fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPath = '1. Back Translation/1. Google Translator/ValidReviewsTranslationsEsFrFrJaJaRuRuEs.txt'\n",
    "invalidPath = '1. Back Translation/1. Google Translator/InvalidReviewsTranslationsEsFrFrJaJaRuRuEs.txt'\n",
    "\n",
    "validEsFrFrJaJaRuRuEsList = importFromTxtToList(validPath)\n",
    "invalidEsFrFrJaJaRuRuEsList = importFromTxtToList(invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f49a67-e058-4a6a-b5d0-9c88c47f3052",
   "metadata": {},
   "source": [
    "Para cada frase del conjunto de datos original (las frases con las reseñas válidas e inválidas), se va a calcular la similitud semántica (usando a un modelo basado en SBERT, conocido como MiniLM, que es más ligero y rápido consiguiendo resultados bastante certeros) y léxica con sus tres correspondientes frases generadas mediante el métodod de retrotraducción. Se van a seleccionar las frases que tengan mayor similitud semántica y menor similitud léxica y se van a guardar en un fichero para su posterior uso.\n",
    "\n",
    "Se van a generar dos ficheros: un csv con dos elementos por fila (la frase original y la retrotraducción escogida) y el otro con solo las retrotraducciones seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a0918b-a1c2-4f87-8628-dc0db6ffe124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#originalDataList: list of texts representing the original dataset\n",
    "#allAugmentedDataList: list of list of texts representing the aumented data \n",
    "#(allAugmentedDataList = [augmentedDataList1, ... ,augmentedDataListN], where augmentedDataList = [augmentedData1, ..., augmentedDataM])\n",
    "#pathWithOriginal: path of the csv with two columns (the original text and the best augmented text)\n",
    "#pathAugmentedData: path of the file with only the augmented data (without the original text)\n",
    "def processAugmentation(originalDataList, allAugmentedDataList, pathWithOriginal, pathAugmentedData):\n",
    "    #Select the model for the semantic similarity\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    #Open the files in which the augmented data will be strored\n",
    "    withOriginalFile = open(pathWithOriginal, \"w\", encoding=\"utf-8\")\n",
    "    augmentedDataFile = open(pathAugmentedData, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    #Write the titles of the csv\n",
    "    withOriginalFile.write(\"OriginalText,AugmentedText,SemanticSimilarity,LexicalSimilarity\\n\")\n",
    "    \n",
    "    resul = []\n",
    "    #Analize every phrase in the original data\n",
    "    for i, originalText in enumerate(originalDataList):\n",
    "        allAugmentedDataInfoDict = {}\n",
    "        bestIdx = 1\n",
    "        \n",
    "        #Analize every traduction\n",
    "        for j, augmentedDataList in enumerate(allAugmentedDataList):\n",
    "            #Compute the similarities of the corresponding traduction\n",
    "            semanticSimilarity = getSemanticSimilarity(originalText, augmentedDataList[i], model)\n",
    "            lexicalSimilarity = getLexicalSimilarity(originalText, augmentedDataList[i])\n",
    "\n",
    "            #Save the traduction and the similarities in a dictionary\n",
    "            allAugmentedDataInfoDict.update({\n",
    "                f\"augmented{j + 1}\": augmentedDataList[i],\n",
    "                f\"semanticSimilarity{j + 1}\": semanticSimilarity,\n",
    "                f\"lexicalSimilarity{j + 1}\": lexicalSimilarity\n",
    "            })\n",
    "\n",
    "            #Get the index of the traduction with greater semantic similarity and less lexical similarity\n",
    "            bestIdx = max(bestIdx, j + 1,\n",
    "                key = lambda k: (allAugmentedDataInfoDict[f\"semanticSimilarity{k}\"] - allAugmentedDataInfoDict[f\"lexicalSimilarity{k}\"])\n",
    "            )\n",
    "\n",
    "        #Select the information of the best augmentation\n",
    "        info = {\n",
    "            \"originalText\": originalText,\n",
    "            \"bestAugmentation\": allAugmentedDataInfoDict[f\"augmented{bestIdx}\"],\n",
    "            \"bestAugmentedDataSemanticSimilarity\": allAugmentedDataInfoDict[f\"semanticSimilarity{bestIdx}\"],\n",
    "            \"bestAugmentedDataLexicalSimiliratity\": allAugmentedDataInfoDict[f\"lexicalSimilarity{bestIdx}\"]\n",
    "        }\n",
    "        info.update(allAugmentedDataInfoDict)\n",
    "\n",
    "        #Save the information\n",
    "        resul.append(info)\n",
    "\n",
    "        #Write the information in the files\n",
    "        withOriginalFile.write(originalText + \",\" + allAugmentedDataInfoDict[f\"augmented{bestIdx}\"] + \",\" + str(allAugmentedDataInfoDict[f\"semanticSimilarity{bestIdx}\"]) + \",\" + str(allAugmentedDataInfoDict[f\"lexicalSimilarity{bestIdx}\"]) + \"\\n\")\n",
    "        #If the text is not empty write it on  the file\n",
    "        if allAugmentedDataInfoDict[f\"augmented{bestIdx}\"]  != '\"\"':\n",
    "            augmentedDataFile.write(allAugmentedDataInfoDict[f\"augmented{bestIdx}\"] + \"\\n\")\n",
    "\n",
    "    #Close the files\n",
    "    withOriginalFile.close()\n",
    "    augmentedDataFile.close()\n",
    "    \n",
    "    return resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5dc006b-52fc-45e1-9c46-af3329c88d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "validWithOriginalPath = '1. Back Translation/3. Augmented Data/ValidBackTranslationWithOriginal.csv'\n",
    "validAugmentedPath = '1. Back Translation/3. Augmented Data/ValidBackTranslationData.txt'\n",
    "invalidWithOriginalPath = '1. Back Translation/3. Augmented Data/InvalidBackTranslationWithOriginal.csv'\n",
    "invalidAugmentedPath = '1. Back Translation/3. Augmented Data/InvalidBackTranslationData.txt'\n",
    "\n",
    "infoValid = processAugmentation(validOriginal, [validEsEnEnEsTraductionList, validEsJaJaEsTraductionList, validEsFrFrJaJaRuRuEsList], validWithOriginalPath, validAugmentedPath)\n",
    "infoValidDF = pd.DataFrame(infoValid)\n",
    "infoInvalid = processAugmentation(invalidOriginal, [invalidEsEnEnEsTraductionList, invalidEsJaJaEsTraductionList, invalidEsFrFrJaJaRuRuEsList], invalidWithOriginalPath, invalidAugmentedPath)\n",
    "infoInvalidDF = pd.DataFrame(infoInvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72d7a1d5-4171-4400-adf0-7f0e407f8ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>“Es de fácil acceso para personas con discapac...</td>\n",
       "      <td>0.854630</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>“Tiene fácil acceso para personas con movilida...</td>\n",
       "      <td>0.978443</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>“Es de fácil acceso para personas con movilida...</td>\n",
       "      <td>0.925599</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>“Es de fácil acceso para personas con discapac...</td>\n",
       "      <td>0.854630</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>\"Espero que hayas mejorado\"</td>\n",
       "      <td>0.916635</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>\"Espero que hayas mejorado\"</td>\n",
       "      <td>0.916635</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>\"Espero que las cosas estén mejorando\".</td>\n",
       "      <td>0.785516</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>\"Espero que la situación esté mejorando\".</td>\n",
       "      <td>0.736162</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>“Además de que esta estación es antigua y tien...</td>\n",
       "      <td>0.932238</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>“La estación es antigua, además de tener una ú...</td>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>“La estación es antigua e inaccesible para per...</td>\n",
       "      <td>0.932935</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>“Además de que esta estación es antigua y tien...</td>\n",
       "      <td>0.932238</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>\"Maravilloso confort\"</td>\n",
       "      <td>0.415461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"Bonito y cómodo\"</td>\n",
       "      <td>0.955331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Maravilloso confort\"</td>\n",
       "      <td>0.415461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>“Muy conveniente”</td>\n",
       "      <td>0.229466</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                        \"Espero que hayan mejorais\"   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                             \"Bien\"   \n",
       "4                                    \"Bonito comodo\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  “Es de fácil acceso para personas con discapac...   \n",
       "1                        \"Espero que hayas mejorado\"   \n",
       "2  “Además de que esta estación es antigua y tien...   \n",
       "3                                             \"Bien\"   \n",
       "4                              \"Maravilloso confort\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.854630                              0.450000   \n",
       "1                             0.916635                              0.200000   \n",
       "2                             0.932238                              0.393939   \n",
       "3                             1.000000                              1.000000   \n",
       "4                             0.415461                              0.000000   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  “Tiene fácil acceso para personas con movilida...             0.978443   \n",
       "1                        \"Espero que hayas mejorado\"             0.916635   \n",
       "2  “La estación es antigua, además de tener una ú...             0.883212   \n",
       "3                                             \"Bien\"             1.000000   \n",
       "4                                  \"Bonito y cómodo\"             0.955331   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0            0.812500  “Es de fácil acceso para personas con movilida...   \n",
       "1            0.200000            \"Espero que las cosas estén mejorando\".   \n",
       "2            0.592593  “La estación es antigua e inaccesible para per...   \n",
       "3            1.000000                                             \"bien\"   \n",
       "4            1.000000                              \"Maravilloso confort\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.925599            0.611111   \n",
       "1             0.785516            0.166667   \n",
       "2             0.932935            0.419355   \n",
       "3             1.000000            1.000000   \n",
       "4             0.415461            0.000000   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  “Es de fácil acceso para personas con discapac...             0.854630   \n",
       "1          \"Espero que la situación esté mejorando\".             0.736162   \n",
       "2  “Además de que esta estación es antigua y tien...             0.932238   \n",
       "3                                             \"bien\"             1.000000   \n",
       "4                                  “Muy conveniente”             0.229466   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0            0.450000  \n",
       "1            0.200000  \n",
       "2            0.393939  \n",
       "3            1.000000  \n",
       "4            0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoValidDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "670d35a6-0253-4468-b6c4-d98e85abf51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>“Vivo en esta zona desde hace 35 años y recono...</td>\n",
       "      <td>0.695063</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>“Llevo 35 años viviendo en el barrio y reconoz...</td>\n",
       "      <td>0.949282</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>\"He vivido en esta zona durante 35 años y reco...</td>\n",
       "      <td>0.818717</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>“Vivo en esta zona desde hace 35 años y recono...</td>\n",
       "      <td>0.695063</td>\n",
       "      <td>0.322581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>\"Ubicación con muchos bares interesantes\"</td>\n",
       "      <td>0.793883</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"Ubicación con muchos bares interesantes\"</td>\n",
       "      <td>0.793883</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"Ubicación con muchos bares interesantes\"</td>\n",
       "      <td>0.793883</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>“Un lugar con muchos bares interesantes”</td>\n",
       "      <td>0.685196</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"…\"</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>0.905728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>0.905728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"...\"</td>\n",
       "      <td>0.838349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>0.905728</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>\"Es una comida muy deliciosa\".</td>\n",
       "      <td>0.644577</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>\"Comida muy deliciosa..\"</td>\n",
       "      <td>0.677902</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"Es una comida muy deliciosa\".</td>\n",
       "      <td>0.644577</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>“Comida muy sabrosa.”</td>\n",
       "      <td>0.706546</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>\"Estación de metro\"</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>\"Estación de metro\"</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>\"estación de metro\"</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>\"estación de metro\"</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1       \"localización con muchos bares interesantes\"   \n",
       "2                                                \"…\"   \n",
       "3                                \"Muy rica comida..\"   \n",
       "4                               \"Estación del.metro\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  “Vivo en esta zona desde hace 35 años y recono...   \n",
       "1          \"Ubicación con muchos bares interesantes\"   \n",
       "2                                                 \"\"   \n",
       "3                     \"Es una comida muy deliciosa\".   \n",
       "4                                \"Estación de metro\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.695063                              0.322581   \n",
       "1                             0.793883                              0.500000   \n",
       "2                             0.905728                              0.000000   \n",
       "3                             0.644577                              0.400000   \n",
       "4                             0.963894                              0.333333   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  “Llevo 35 años viviendo en el barrio y reconoz...             0.949282   \n",
       "1          \"Ubicación con muchos bares interesantes\"             0.793883   \n",
       "2                                                 \"\"             0.905728   \n",
       "3                           \"Comida muy deliciosa..\"             0.677902   \n",
       "4                                \"Estación de metro\"             0.963894   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0            0.629630  \"He vivido en esta zona durante 35 años y reco...   \n",
       "1            0.500000          \"Ubicación con muchos bares interesantes\"   \n",
       "2            0.000000                                              \"...\"   \n",
       "3            0.500000                     \"Es una comida muy deliciosa\".   \n",
       "4            0.333333                                \"estación de metro\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.818717            0.448276   \n",
       "1             0.793883            0.500000   \n",
       "2             0.838349            0.000000   \n",
       "3             0.644577            0.400000   \n",
       "4             0.963894            0.333333   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  “Vivo en esta zona desde hace 35 años y recono...             0.695063   \n",
       "1           “Un lugar con muchos bares interesantes”             0.685196   \n",
       "2                                                 \"\"             0.905728   \n",
       "3                              “Comida muy sabrosa.”             0.706546   \n",
       "4                                \"estación de metro\"             0.963894   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0            0.322581  \n",
       "1            0.500000  \n",
       "2            0.000000  \n",
       "3            0.500000  \n",
       "4            0.333333  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoInvalidDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf741edf-ec0d-4341-8de9-496e46fabf6c",
   "metadata": {},
   "source": [
    "Como se puede ver, el método de retrotraducción genera frases con una similitud semántica muy parecida pero con gran variavilidad en la similitud léxica. Por lo tanto, se consiguen frases con distinto vocabulario pero mismo significado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd28f2b-34c8-4672-ba82-8bf50710dd15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reemplazo por sinónimos\n",
    "\n",
    "Este método consiste en elejir aleatoriamente n palabras del texto que no sean palabras vacías, y reemplazar cada una de estas palabras por uno de sus sinónimos elegido al azar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa6c88-9d18-48d6-a8e6-dec71fdcc744",
   "metadata": {},
   "source": [
    "Esta función, dada una palabra devuelve, si existe, un sinónimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b349e9a-15e2-4691-b13c-29e48f62a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swaps the word given by its synonym\n",
    "def swapSynonym(word):\n",
    "    #gets all synonyms from the word given\n",
    "    synset = wordnet.synsets(word, lang='spa')\n",
    "    if synset:\n",
    "        #if the word has one or more synonym we swap it\n",
    "        synset = wordnet.synsets(word, lang='spa')[0]\n",
    "        synonymsList = synset.lemma_names('spa') \n",
    "        cleanList = [synonym.replace('_', ' ').strip() for synonym in synonymsList]\n",
    "        #filter to make sure its a diferent word\n",
    "        differentList = [s for s in cleanList if s.lower() != word.lower()]\n",
    "        #choose a random synonym if the word has one\n",
    "        if differentList:\n",
    "            chosen = random.choice(differentList)\n",
    "            return chosen\n",
    "        else:\n",
    "            return word\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d33496-f7e1-466b-ad8b-4477a9c095e0",
   "metadata": {},
   "source": [
    "Dado un texto, cambia con un prob% de probabilidad las palabras no vacías por un sinónimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "156c4503-cac2-4543-ad6d-6ab8ae514d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapBySynonymLine(line, prob):\n",
    "    # Split the line into individual words\n",
    "    words = line.split();\n",
    "    newWords = []\n",
    "\n",
    "    #Get the spanish stop words\n",
    "    spanishStopWords = getSpanishStopWords()\n",
    "\n",
    "    #Analyze all the words in the given text\n",
    "    for word in words:\n",
    "        # Check if the word is not a stop word\n",
    "        if word not in spanishStopWords: \n",
    "            # With prob probability, replace the word with a synonym\n",
    "            if random.random() <= prob:\n",
    "                newWord = swapSynonym(word)\n",
    "            else: \n",
    "                newWord = word\n",
    "            newWords.append(newWord)\n",
    "        else:\n",
    "            newWords.append(word)\n",
    "    # Join the words back into a single line and return it\n",
    "    return ' '.join(newWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f640ff-e8e3-4ad0-a50e-449195994063",
   "metadata": {},
   "source": [
    "Dado una lista de textos y una ruta, aplica el métododo de sustitución por sinónimos a todos los elementos de la lista y los alamacena en la ruta proporcionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5bbee92-a4ab-4fb8-af1b-3af832c66b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#synonym replacement method\n",
    "def synonymReplacement(textList, prob, targetPath):\n",
    "    #Open the file\n",
    "    targetFile = open(targetPath, \"w\", encoding = \"utf-8\")\n",
    "    \n",
    "    newList = []\n",
    "    for line in textList:\n",
    "        newLine = swapBySynonymLine(line, prob)\n",
    "        newList.append(newLine)\n",
    "        targetFile.write(newLine + \"\\n\")\n",
    "\n",
    "    #Close the file\n",
    "    targetFile.close()\n",
    "    \n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beba2eee-ee0e-4f8b-833c-5b31569e1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFromTxtToList(source):\n",
    "    with open(source, 'r', encoding=\"utf-8\") as file:\n",
    "        #Generate a list with all the reviews\n",
    "        targetList = [line.strip() for line in file]\n",
    "    return targetList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe593df-ec69-4a56-90d2-51e350e55a57",
   "metadata": {},
   "source": [
    "Se va a aplicar el método de reemplazo por sinónimos tres veces para generar tres conjuntos de datos diferentes. Además, la probabilidad de sustitución por sinónimo va a aumentar en cada conjunto de datos: inicialmente 0.25, después 0.45 y finalmente 0.65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34c8a63c-fd48-4704-a922-a466d6c7dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the original data\n",
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) \n",
    "\n",
    "#Apply the synonym replacement 3 times to both datasets\n",
    "for i in range(3):\n",
    "    validPath = f\"3. Synonym Replacement/1. All Augmented Data/validSynonymsReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"3. Synonym Replacement/1. All Augmented Data/invalidSynonymsReviews{i + 1}.txt\"\n",
    "\n",
    "    prob = 0.25 + 2 * i / 10\n",
    "    \n",
    "    synonymReplacement(validOriginal, prob, validPath)\n",
    "    synonymReplacement(invalidOriginal, prob, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44359ec6-da25-440e-9987-6bdfe37bb705",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Análisis del reemplazo por sinónimos y selección de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df32aa-0194-46c1-a2fa-92aee28a8597",
   "metadata": {},
   "source": [
    "Importar los datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb253981-d4c4-40e2-b1c1-8ad911c8c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6e36c-9306-4eff-87fd-bc1c4f0f9610",
   "metadata": {},
   "source": [
    "Importar los tres datasets generados en el reemplazo por sinónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bb530ae-286a-4d8b-b8aa-2fd2543997e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the data \n",
    "validSynonymReplacementList = []\n",
    "invalidSynonymReplacementList = []\n",
    "for i in range(3):\n",
    "    validPath = f\"3. Synonym Replacement/1. All Augmented Data/validSynonymsReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"3. Synonym Replacement/1. All Augmented Data/invalidSynonymsReviews{i + 1}.txt\"\n",
    "\n",
    "    validSynonymReplacementList.append(importFromTxtToList(validPath))\n",
    "    invalidSynonymReplacementList.append(importFromTxtToList(invalidPath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b50528d-a507-4b59-9484-c8edfc4cbd4b",
   "metadata": {},
   "source": [
    "Realizar el análisis y la selección de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bb43223-e110-41c0-ab34-de40ca92a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "validWithOriginalPath = '3. Synonym Replacement/2. Augmented Data/ ValidSynonymReplacementWithOriginal.csv'\n",
    "validAugmentedPath = '3. Synonym Replacement/2. Augmented Data/ValidSynonymReplacementData.txt'\n",
    "invalidWithOriginalPath = '3. Synonym Replacement/2. Augmented Data/InvalidSynonymReplacementWithOriginal.csv'\n",
    "invalidAugmentedPath = '3. Synonym Replacement/2. Augmented Data/InvalidSynonymReplacementData.txt'\n",
    "\n",
    "infoValid = processAugmentation(validOriginal, validSynonymReplacementList, validWithOriginalPath, validAugmentedPath)\n",
    "infoValidDF = pd.DataFrame(infoValid)\n",
    "infoInvalid = processAugmentation(invalidOriginal, invalidSynonymReplacementList, invalidWithOriginalPath, invalidAugmentedPath)\n",
    "infoInvalidDF = pd.DataFrame(infoInvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c678ed-7527-4a2c-9cd3-77300176f6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>\"Tiene fácil entrada para las personas con mov...</td>\n",
       "      <td>0.989551</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Tiene fácil entrada para las personas con mov...</td>\n",
       "      <td>0.989551</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>0.988377</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>\"La estación es antigua, a un lado de parir un...</td>\n",
       "      <td>0.805127</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>0.949019</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>\"La estación es antigua, a un lado de tener un...</td>\n",
       "      <td>0.952585</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>\"La estación es antigua, a un lado de parir un...</td>\n",
       "      <td>0.805127</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                        \"Espero que hayan mejorais\"   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                             \"Bien\"   \n",
       "4                                    \"Bonito comodo\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"Tiene fácil entrada para las personas con mov...   \n",
       "1                        \"Espero que hayan mejorais\"   \n",
       "2  \"La estación es antigua, a un lado de parir un...   \n",
       "3                                             \"Bien\"   \n",
       "4                                    \"Bonito comodo\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.989551                              0.875000   \n",
       "1                             1.000000                              1.000000   \n",
       "2                             0.805127                              0.516129   \n",
       "3                             1.000000                              1.000000   \n",
       "4                             1.000000                              1.000000   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...             1.000000   \n",
       "1                        \"Espero que hayan mejorais\"             1.000000   \n",
       "2  \"La estación es antigua, aparte de tener una s...             0.949019   \n",
       "3                                             \"Bien\"             1.000000   \n",
       "4                                    \"Bonito comodo\"             1.000000   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0            1.000000  \"Tiene fácil entrada para las personas con mov...   \n",
       "1            1.000000                        \"Espero que hayan mejorais\"   \n",
       "2            0.833333  \"La estación es antigua, a un lado de tener un...   \n",
       "3            1.000000                                             \"Bien\"   \n",
       "4            1.000000                                    \"Bonito comodo\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.989551            0.875000   \n",
       "1             1.000000            1.000000   \n",
       "2             0.952585            0.692308   \n",
       "3             1.000000            1.000000   \n",
       "4             1.000000            1.000000   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...             0.988377   \n",
       "1                        \"Espero que hayan mejorais\"             1.000000   \n",
       "2  \"La estación es antigua, a un lado de parir un...             0.805127   \n",
       "3                                             \"Bien\"             1.000000   \n",
       "4                                    \"Bonito comodo\"             1.000000   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0            0.875000  \n",
       "1            1.000000  \n",
       "2            0.516129  \n",
       "3            1.000000  \n",
       "4            1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoValidDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3b5eb25-2f87-472f-b189-b59d3a5afcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>\"He vivido 35 largo tiempo en el barrio y reco...</td>\n",
       "      <td>0.920601</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>\"He vivido 35 largo tiempo en el barrio y reco...</td>\n",
       "      <td>0.926218</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>\"He vivido 35 largo tiempo en el barrio y reco...</td>\n",
       "      <td>0.920601</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>\"He vivido 35 mucho tiempo en el barrio y reco...</td>\n",
       "      <td>0.986137</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"…\"</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1       \"localización con muchos bares interesantes\"   \n",
       "2                                                \"…\"   \n",
       "3                                \"Muy rica comida..\"   \n",
       "4                               \"Estación del.metro\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"He vivido 35 largo tiempo en el barrio y reco...   \n",
       "1       \"localización con muchos bares interesantes\"   \n",
       "2                                                \"…\"   \n",
       "3                                \"Muy rica comida..\"   \n",
       "4                               \"Estación del.metro\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.920601                              0.703704   \n",
       "1                             1.000000                              1.000000   \n",
       "2                             1.000000                              0.000000   \n",
       "3                             1.000000                              1.000000   \n",
       "4                             1.000000                              1.000000   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"He vivido 35 largo tiempo en el barrio y reco...             0.926218   \n",
       "1       \"localización con muchos bares interesantes\"             1.000000   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                                \"Muy rica comida..\"             1.000000   \n",
       "4                               \"Estación del.metro\"             1.000000   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0            0.769231  \"He vivido 35 largo tiempo en el barrio y reco...   \n",
       "1            1.000000       \"localización con muchos bares interesantes\"   \n",
       "2            0.000000                                                \"…\"   \n",
       "3            1.000000                                \"Muy rica comida..\"   \n",
       "4            1.000000                               \"Estación del.metro\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.920601            0.703704   \n",
       "1             1.000000            1.000000   \n",
       "2             1.000000            0.000000   \n",
       "3             1.000000            1.000000   \n",
       "4             1.000000            1.000000   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"He vivido 35 mucho tiempo en el barrio y reco...             0.986137   \n",
       "1       \"localización con muchos bares interesantes\"             1.000000   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                                \"Muy rica comida..\"             1.000000   \n",
       "4                               \"Estación del.metro\"             1.000000   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0                 0.8  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 1.0  \n",
       "4                 1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoInvalidDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c42cda7-c1da-491a-a27d-690cc265803a",
   "metadata": {},
   "source": [
    "A diferencia de la retrotraducción, este método no genera variabilidad léxica. No altera el significado de la frase, pero tampoco altera las palabras que la componen. Creemos que esto se debe a la reducida capacidad de la librelia nltk para palabras en castellano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3141c50-b5e9-437e-9da8-73265ee193c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inserción aleatoria\n",
    "\n",
    "Este método consiste en encontrar un sinónimo aleatorio de una palabra aleatoria en la oración que no sea una palabra vacía e insertar ese sinónimo en una posición aleatoria de la oración."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af13b666-95df-4f5c-9d84-89ce123e19d0",
   "metadata": {},
   "source": [
    "Función para calcular el número de modificaciones (inserciones, eliminaciones, sustituciones ...) de un texto dado dependiendo de su longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2cc69e-928e-4743-8368-e22d1fbbbb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the number of insertions or replacements or deletions on a given text depending on its length\n",
    "def calculateModifications(text):\n",
    "    return max(1, int(len(text.split()) * 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b031f-1716-4045-a258-a798d30b3d0e",
   "metadata": {},
   "source": [
    "Función para añadir dobles comillas al inicio y al final del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10424487-e839-49d6-89a3-4e761b9304f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add quotes to the given text\n",
    "def addQuotes(text):\n",
    "    return f'\"{text}\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5e60f-d3f9-4b44-85ed-fe5f9e080185",
   "metadata": {},
   "source": [
    "Función para eliminar las dobles comillas del inicio y el final de un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19a74aab-2583-4ac7-95b4-2f7a8b663680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove quotes from the given text\n",
    "def removeQuotes(text):\n",
    "    if text.startswith('\"') and text.endswith('\"'):\n",
    "        return text[1:-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec271714-e2cf-4073-90aa-bb1f841c195c",
   "metadata": {},
   "source": [
    "Función que realiza la inserción aleatoria de un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db70cb0c-60f1-4c45-83f2-2e9e7003968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that executes the random insertion on a given text\n",
    "def wordInsertion(text):\n",
    "    #Split the text\n",
    "    wordsList = text.split()   \n",
    "    \n",
    "    # Clean the line of text and remove extra spaces or special characters\n",
    "    cleanTextStr = cleanText(text)\n",
    "    \n",
    "    # Remove Spanish stop words and split the result into words\n",
    "    withoutStopWordsList = revomeSpanishStopWords(cleanTextStr).split() \n",
    "    \n",
    "    # Proceed only if there are words left after removing stop words\n",
    "    if withoutStopWordsList:\n",
    "        # Determine the number of insertions based on line length\n",
    "        for i in range(calculateModifications(text)):\n",
    "            # Choose a random important word from the list without stop words\n",
    "            chosen = random.choice(withoutStopWordsList)    \n",
    "            # Get a synonym of the chosen word\n",
    "            synonym = swapSynonym(chosen) \n",
    "            # Choose a random position to insert the synonym\n",
    "            pos = random.randint(0, len(wordsList))    \n",
    "            # Insert the synonym at the chosen position, removing any extra spaces\n",
    "            wordsList.insert(pos, synonym.strip())   \n",
    "            \n",
    "    # Return the modified line with quotation marks around it\n",
    "    return ' '.join(wordsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e853d08-4ec1-4371-9ea3-039c39c1322d",
   "metadata": {},
   "source": [
    "Función que realiza la inserción aleatoria a todos los elementos de una lista de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "592f6148-d4b8-48ad-9d03-bf674df3bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that executes the random insertion to all the elements of a list of texts and strores it in a file\n",
    "def randomInsertion(textList, targetPath):\n",
    "    #Open the file\n",
    "    targetFile = open(targetPath, \"w\", encoding = \"utf-8\")\n",
    "    \n",
    "    newList = []\n",
    "    for text in textList:\n",
    "        newLine = wordInsertion(text)\n",
    "        newList.append(newLine)\n",
    "        targetFile.write(newLine + \"\\n\")\n",
    "\n",
    "    #Close the file\n",
    "    targetFile.close()\n",
    "    \n",
    "    return newList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13bd606-ecef-4f6c-9295-424463837901",
   "metadata": {},
   "source": [
    "Se va a realizar este proceso tres veces para generar más textos distintos de los que se posteriormente se elegirán los mejores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd806145-45f9-4b85-ab6f-4624b24c3520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the original data\n",
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) \n",
    "\n",
    "#Apply the synonym replacement 3 times to both datasets\n",
    "for i in range(3):\n",
    "    validPath = f\"4. Random Insertion/1. All Augmented Data/validRandomInsertionReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"4. Random Insertion/1. All Augmented Data/invalidRandomInsertionReviews{i + 1}.txt\"\n",
    "\n",
    "    \n",
    "    randomInsertion(validOriginal, validPath)\n",
    "    randomInsertion(invalidOriginal, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a3e6fe-55c7-484d-99a1-9d606b5d74aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Análisis de la inserción aleatoria y selección de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532723c8-779d-47b8-820e-5a1bdec24068",
   "metadata": {},
   "source": [
    "Importar los datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c3ec6b-0764-4532-bc63-4b7c20f8a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d1e9d-abe1-4a3c-aacf-b25e303f8570",
   "metadata": {},
   "source": [
    "Importar los datasets generados en la inserción aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c0de326-d0d3-44b1-9b3d-1b2a7f63b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the data \n",
    "validRandomInsertionList = []\n",
    "invalidRandomInsertionList = []\n",
    "for i in range(3):\n",
    "    validPath = f\"4. Random Insertion/1. All Augmented Data/validRandomInsertionReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"4. Random Insertion/1. All Augmented Data/invalidRandomInsertionReviews{i + 1}.txt\"\n",
    "\n",
    "    validRandomInsertionList.append(importFromTxtToList(validPath))\n",
    "    invalidRandomInsertionList.append(importFromTxtToList(invalidPath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad86aa79-5ba6-41f7-b726-48594edbcd6a",
   "metadata": {},
   "source": [
    "Realizar el análisis y la selección de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a2d6285-e4a4-4f74-ac74-b7d56f2ad6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "validWithOriginalPath = '4. Random Insertion/2. Augmented Data/ ValidRandomInsertionWithOriginal.csv'\n",
    "validAugmentedPath = '4. Random Insertion/2. Augmented Data/ValidRandomInsertionData.txt'\n",
    "invalidWithOriginalPath = '4. Random Insertion/2. Augmented Data/InvalidRandomInsertionWithOriginal.csv'\n",
    "invalidAugmentedPath = '4. Random Insertion/2. Augmented Data/InvalidRandomInsertionData.txt'\n",
    "\n",
    "infoValid = processAugmentation(validOriginal, validRandomInsertionList, validWithOriginalPath, validAugmentedPath)\n",
    "infoValidDF = pd.DataFrame(infoValid)\n",
    "infoInvalid = processAugmentation(invalidOriginal, invalidRandomInsertionList, invalidWithOriginalPath, invalidAugmentedPath)\n",
    "infoInvalidDF = pd.DataFrame(infoInvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3543b70f-dda4-40ef-b06c-3850e8a660da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>0.993096</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>\"Tiene julian fácil acceso para las personas c...</td>\n",
       "      <td>0.958814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Tiene fácil acceso otro para las personas con...</td>\n",
       "      <td>0.965412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>0.993096</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>\"Espero que hayan mejorais\" hayan</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>espero \"Espero que hayan mejorais\"</td>\n",
       "      <td>0.977621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Espero que hayan mejorais\" hayan</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Espero hayan que hayan mejorais\"</td>\n",
       "      <td>0.987335</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>0.986128</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>0.986128</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>0.978366</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una a...</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>\"Bien\" bien</td>\n",
       "      <td>0.956442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\" bien</td>\n",
       "      <td>0.956442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\" bien</td>\n",
       "      <td>0.956442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\" bien</td>\n",
       "      <td>0.956442</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>precioso \"Bonito comodo\"</td>\n",
       "      <td>0.932838</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>precioso \"Bonito comodo\"</td>\n",
       "      <td>0.932838</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"Bonito comodo comodo\"</td>\n",
       "      <td>0.973187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bonito comodo\" comodo</td>\n",
       "      <td>0.978755</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                        \"Espero que hayan mejorais\"   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                             \"Bien\"   \n",
       "4                                    \"Bonito comodo\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                  \"Espero que hayan mejorais\" hayan   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                        \"Bien\" bien   \n",
       "4                           precioso \"Bonito comodo\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.993096                              0.937500   \n",
       "1                             0.988550                              1.000000   \n",
       "2                             0.986128                              0.880000   \n",
       "3                             0.956442                              1.000000   \n",
       "4                             0.932838                              0.666667   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"Tiene julian fácil acceso para las personas c...             0.958814   \n",
       "1                 espero \"Espero que hayan mejorais\"             0.977621   \n",
       "2  \"La estación es antigua, aparte de tener una s...             0.986128   \n",
       "3                                        \"Bien\" bien             0.956442   \n",
       "4                           precioso \"Bonito comodo\"             0.932838   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0            1.000000  \"Tiene fácil acceso otro para las personas con...   \n",
       "1            1.000000                  \"Espero que hayan mejorais\" hayan   \n",
       "2            0.880000  \"La estación es antigua, aparte de tener una s...   \n",
       "3            1.000000                                        \"Bien\" bien   \n",
       "4            0.666667                             \"Bonito comodo comodo\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.965412            1.000000   \n",
       "1             0.988550            1.000000   \n",
       "2             0.978366            0.916667   \n",
       "3             0.956442            1.000000   \n",
       "4             0.973187            1.000000   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...             0.993096   \n",
       "1                  \"Espero hayan que hayan mejorais\"             0.987335   \n",
       "2  \"La estación es antigua, aparte de tener una a...             0.968685   \n",
       "3                                        \"Bien\" bien             0.956442   \n",
       "4                             \"Bonito comodo\" comodo             0.978755   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0            0.937500  \n",
       "1            1.000000  \n",
       "2            0.916667  \n",
       "3            1.000000  \n",
       "4            1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoValidDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92b380ef-24b0-4abe-a627-53dbf32e9a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>\"He vivido dolor 35 años en joven el barrio y ...</td>\n",
       "      <td>0.980646</td>\n",
       "      <td>0.88</td>\n",
       "      <td>\"He vivido dolor 35 años en joven el barrio y ...</td>\n",
       "      <td>0.980646</td>\n",
       "      <td>0.88</td>\n",
       "      <td>\"He zonas joven vivido 35 años en el barrio y ...</td>\n",
       "      <td>0.946283</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"He vivido 35 años en el zonas barrio desapare...</td>\n",
       "      <td>0.967516</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>\"localización con bares muchos bares interesan...</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"localización bares con muchos bares interesan...</td>\n",
       "      <td>0.974223</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"localización con muchos bares bares interesan...</td>\n",
       "      <td>0.966685</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"localización con bares muchos bares interesan...</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"…\"</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>\"Muy rica comida..\" sustancialmente</td>\n",
       "      <td>0.935908</td>\n",
       "      <td>0.75</td>\n",
       "      <td>\"Muy rica sustancialmente comida..\"</td>\n",
       "      <td>0.878053</td>\n",
       "      <td>0.75</td>\n",
       "      <td>\"Muy rica comida..\" sustancialmente</td>\n",
       "      <td>0.935908</td>\n",
       "      <td>0.75</td>\n",
       "      <td>alimento \"Muy rica comida..\"</td>\n",
       "      <td>0.929850</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>\"Estación estacion del.metro\"</td>\n",
       "      <td>0.980573</td>\n",
       "      <td>1.00</td>\n",
       "      <td>estacion \"Estación del.metro\"</td>\n",
       "      <td>0.972385</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"Estación del.metro\" estacion</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"Estación estacion del.metro\"</td>\n",
       "      <td>0.980573</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1       \"localización con muchos bares interesantes\"   \n",
       "2                                                \"…\"   \n",
       "3                                \"Muy rica comida..\"   \n",
       "4                               \"Estación del.metro\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"He vivido dolor 35 años en joven el barrio y ...   \n",
       "1  \"localización con bares muchos bares interesan...   \n",
       "2                                                \"…\"   \n",
       "3                \"Muy rica comida..\" sustancialmente   \n",
       "4                      \"Estación estacion del.metro\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.980646                                  0.88   \n",
       "1                             0.977484                                  1.00   \n",
       "2                             1.000000                                  0.00   \n",
       "3                             0.935908                                  0.75   \n",
       "4                             0.980573                                  1.00   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"He vivido dolor 35 años en joven el barrio y ...             0.980646   \n",
       "1  \"localización bares con muchos bares interesan...             0.974223   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                \"Muy rica sustancialmente comida..\"             0.878053   \n",
       "4                      estacion \"Estación del.metro\"             0.972385   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0                0.88  \"He zonas joven vivido 35 años en el barrio y ...   \n",
       "1                1.00  \"localización con muchos bares bares interesan...   \n",
       "2                0.00                                                \"…\"   \n",
       "3                0.75                \"Muy rica comida..\" sustancialmente   \n",
       "4                1.00                      \"Estación del.metro\" estacion   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.946283                1.00   \n",
       "1             0.966685                1.00   \n",
       "2             1.000000                0.00   \n",
       "3             0.935908                0.75   \n",
       "4             0.978640                1.00   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"He vivido 35 años en el zonas barrio desapare...             0.967516   \n",
       "1  \"localización con bares muchos bares interesan...             0.977484   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                       alimento \"Muy rica comida..\"             0.929850   \n",
       "4                      \"Estación estacion del.metro\"             0.980573   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0                1.00  \n",
       "1                1.00  \n",
       "2                0.00  \n",
       "3                0.75  \n",
       "4                1.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoInvalidDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ae238-b3cb-4d07-b0f8-341d1d237680",
   "metadata": {},
   "source": [
    "Como se puede ver, da mejores resultados que el anterior método, pero aun asi hay muy poca variación tanto en la similitud semántica como en la léxica (el mayor de los problemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22b432-8417-4e7d-9c46-4a52e5f79e05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Intercambio aleatorio\n",
    "\n",
    "Este método consiste en cambiar n veces dos palabras aleatoriamente en un texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7436f963-b4c9-4cc0-9cf1-e266eaa4b2f2",
   "metadata": {},
   "source": [
    "Esta función va a coger dos índices aleatorios y distintos de una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97829934-b3cd-4d60-a378-178aca235864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get two different indexes of a list\n",
    "def getRandomIndexes(wordsList):\n",
    "    \n",
    "    # Generate a random index within the range of the words list\n",
    "    pos1 = random.randint(0, len(wordsList) - 1)\n",
    "    \n",
    "    # Keep generating a new index until it is not equal to the first index\n",
    "    pos2 = random.randint(0, len(wordsList) - 1)\n",
    "    while pos1 == pos2:\n",
    "        pos2 = random.randint(0, len(wordsList) - 1)   \n",
    "\n",
    "    #Return both indexes\n",
    "    return pos1, pos2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d79e90-4f18-420d-8a71-51cf9b88f46c",
   "metadata": {},
   "source": [
    "Esta funcion selecciona dos palabras no vacías del texto original y las intercambia. Repite este proceso tantas veces como la función alculateModifications(text) lo indique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5c866c6-4871-4e58-9db9-3a1ed10d3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that selects two non stop words of a text and swaps them. Does this alculateModifications(text) times\n",
    "def wordSwap(text):\n",
    "    #Remove the quotation marks\n",
    "    text = removeQuotes(text)\n",
    "\n",
    "    #Get the list of words of the text\n",
    "    wordsList = text.split()\n",
    "    \n",
    "    #Remove the spanish stop words from the text\n",
    "    withoutStopWordsTextList = revomeSpanishStopWords(text).split()\n",
    "    \n",
    "    # Check if there are more than one none stop words to perform swapping\n",
    "    if len(withoutStopWordsTextList) > 1:\n",
    "        # Loop for the number of modifications calculated for the text\n",
    "        for i in range(calculateModifications(text)):\n",
    "            # Get two diferent random indexes\n",
    "            pos1 , pos2 = getRandomIndexes(withoutStopWordsTextList)\n",
    "\n",
    "            #Update the indexes to match the original text\n",
    "            pos1 = wordsList.index(withoutStopWordsTextList[pos1])\n",
    "            pos2 = wordsList.index(withoutStopWordsTextList[pos2])\n",
    "            \n",
    "            # Swap the words at the two random positions\n",
    "            aux = wordsList[pos1]\n",
    "            wordsList[pos1] = wordsList[pos2]\n",
    "            wordsList[pos2] = aux\n",
    "\n",
    "    \n",
    "    # Return the modified line with quotes added\n",
    "    return addQuotes(' '.join(wordsList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0ea91c-eaea-487d-a22d-19807fae2432",
   "metadata": {},
   "source": [
    "Función que realiza el intercambio aleatorio a todos los elementos de una lista de textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5ece6d8-3259-4517-bcb7-5759783edc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random swap\n",
    "def randomSwap(textList, targetPath):\n",
    "    #Open the file\n",
    "    targetFile = open(targetPath, \"w\", encoding = \"utf-8\")\n",
    "\n",
    "    newList = []\n",
    "    for text in textList:\n",
    "        newText = wordSwap(text)\n",
    "        newList.append(newText)\n",
    "        targetFile.write(newText + \"\\n\")\n",
    "\n",
    "    #Close the file\n",
    "    targetFile.close()\n",
    "    \n",
    "    return newList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0365c26-e77d-439a-8017-e1437b734392",
   "metadata": {},
   "source": [
    "Se va a realizar este proceso tres veces para generar más textos distintos de los que se posteriormente se elegirán los mejores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e42176-1ab7-40b5-9157-f5aac0a6c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the original data\n",
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) \n",
    "\n",
    "#Apply the synonym replacement 3 times to both datasets\n",
    "for i in range(3):\n",
    "    validPath = f\"5. Random Swap/1. All Augmented Data/validRandomSwapReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"5. Random Swap/1. All Augmented Data/invalidRandomSwapReviews{i + 1}.txt\"\n",
    "\n",
    "    \n",
    "    randomSwap(validOriginal, validPath)\n",
    "    randomSwap(invalidOriginal, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab8f82-48b3-434b-86e8-bd112fb91533",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Análisis del intercambio aleatorio y selección de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91d420-094a-46fb-a96d-793ad35c8025",
   "metadata": {},
   "source": [
    "Importar los datos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "673a0d06-0f2e-4ea9-ba2b-8c1c43c4e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd32f0a-8087-4f8f-8481-66496f5e888b",
   "metadata": {},
   "source": [
    "Importar los datasets generados en el intercambio aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdecae3e-bc1a-4e7a-9ccc-3e8b065b5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the data \n",
    "validRandomSwapList = []\n",
    "invalidRandomSwapList = []\n",
    "for i in range(3):\n",
    "    validPath = f\"5. Random Swap/1. All Augmented Data/validRandomSwapReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"5. Random Swap/1. All Augmented Data/invalidRandomSwapReviews{i + 1}.txt\"\n",
    "\n",
    "    validRandomSwapList.append(importFromTxtToList(validPath))\n",
    "    invalidRandomSwapList.append(importFromTxtToList(invalidPath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b00d5e-0728-43a2-ae1e-8a0e67905317",
   "metadata": {},
   "source": [
    "Realizar el análisis y la selección de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89d280cf-d939-4a88-a954-ab255e67eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validWithOriginalPath = '5. Random Swap/2. Augmented Data/ ValidRandomSwapWithOriginal.csv'\n",
    "validAugmentedPath = '5. Random Swap/2. Augmented Data/ValidRandomSwapData.txt'\n",
    "invalidWithOriginalPath = '5. Random Swap/2. Augmented Data/InvalidRandomSwapWithOriginal.csv'\n",
    "invalidAugmentedPath = '5. Random Swap/2. Augmented Data/InvalidRandomSwapData.txt'\n",
    "\n",
    "infoValid = processAugmentation(validOriginal, validRandomSwapList, validWithOriginalPath, validAugmentedPath)\n",
    "infoValidDF = pd.DataFrame(infoValid)\n",
    "infoInvalid = processAugmentation(invalidOriginal, invalidRandomSwapList, invalidWithOriginalPath, invalidAugmentedPath)\n",
    "infoInvalidDF = pd.DataFrame(infoInvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e55b3f8-2e9e-4179-9bd3-221084899593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>\"acceso fácil Tiene para las personas con movi...</td>\n",
       "      <td>0.993650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>0.986013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>0.989630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"acceso fácil Tiene para las personas con movi...</td>\n",
       "      <td>0.993650</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>\"Espero que mejorais hayan\"</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"hayan que Espero mejorais\"</td>\n",
       "      <td>0.989534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Espero que mejorais hayan\"</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"mejorais que hayan Espero\"</td>\n",
       "      <td>0.991634</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una n...</td>\n",
       "      <td>0.995518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una n...</td>\n",
       "      <td>0.995518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"La estación es antigua, aparte de habilitada ...</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"La estación es antigua, pasillo de tener una ...</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>\"comodo Bonito\"</td>\n",
       "      <td>0.988781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"comodo Bonito\"</td>\n",
       "      <td>0.988781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"comodo Bonito\"</td>\n",
       "      <td>0.988781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"comodo Bonito\"</td>\n",
       "      <td>0.988781</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                        \"Espero que hayan mejorais\"   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                             \"Bien\"   \n",
       "4                                    \"Bonito comodo\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"acceso fácil Tiene para las personas con movi...   \n",
       "1                        \"Espero que mejorais hayan\"   \n",
       "2  \"La estación es antigua, aparte de tener una n...   \n",
       "3                                             \"Bien\"   \n",
       "4                                    \"comodo Bonito\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.993650                                   1.0   \n",
       "1                             0.992640                                   1.0   \n",
       "2                             0.995518                                   1.0   \n",
       "3                             1.000000                                   1.0   \n",
       "4                             0.988781                                   1.0   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...             0.986013   \n",
       "1                        \"hayan que Espero mejorais\"             0.989534   \n",
       "2  \"La estación es antigua, aparte de tener una n...             0.995518   \n",
       "3                                             \"Bien\"             1.000000   \n",
       "4                                    \"comodo Bonito\"             0.988781   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0                 1.0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                 1.0                        \"Espero que mejorais hayan\"   \n",
       "2                 1.0  \"La estación es antigua, aparte de habilitada ...   \n",
       "3                 1.0                                             \"Bien\"   \n",
       "4                 1.0                                    \"comodo Bonito\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.989630                 1.0   \n",
       "1             0.992640                 1.0   \n",
       "2             0.993437                 1.0   \n",
       "3             1.000000                 1.0   \n",
       "4             0.988781                 1.0   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"acceso fácil Tiene para las personas con movi...             0.993650   \n",
       "1                        \"mejorais que hayan Espero\"             0.991634   \n",
       "2  \"La estación es antigua, pasillo de tener una ...             0.982857   \n",
       "3                                             \"Bien\"             1.000000   \n",
       "4                                    \"comodo Bonito\"             0.988781   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0                 1.0  \n",
       "1                 1.0  \n",
       "2                 1.0  \n",
       "3                 1.0  \n",
       "4                 1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoValidDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4b74276-cf01-4c1a-8f60-d6177a774b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>\"He gente 35 años en el ha y reconozco que el ...</td>\n",
       "      <td>0.986286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"He gente 35 años en el ha y reconozco que el ...</td>\n",
       "      <td>0.986286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"barrio vivido 35 años en el He y reconozco qu...</td>\n",
       "      <td>0.976794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"He zonas mejoró años en el barrio y reconozco...</td>\n",
       "      <td>0.970291</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>\"interesantes con muchos bares localización\"</td>\n",
       "      <td>0.991607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"interesantes con muchos bares localización\"</td>\n",
       "      <td>0.991607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"bares con muchos localización interesantes\"</td>\n",
       "      <td>0.985325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"interesantes con muchos bares localización\"</td>\n",
       "      <td>0.991607</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"…\"</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>\"rica Muy comida..\"</td>\n",
       "      <td>0.989455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Muy comida.. rica\"</td>\n",
       "      <td>0.980956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"rica Muy comida..\"</td>\n",
       "      <td>0.989455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"comida.. rica Muy\"</td>\n",
       "      <td>0.964634</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>\"del.metro Estación\"</td>\n",
       "      <td>0.988279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"del.metro Estación\"</td>\n",
       "      <td>0.988279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"del.metro Estación\"</td>\n",
       "      <td>0.988279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"del.metro Estación\"</td>\n",
       "      <td>0.988279</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1       \"localización con muchos bares interesantes\"   \n",
       "2                                                \"…\"   \n",
       "3                                \"Muy rica comida..\"   \n",
       "4                               \"Estación del.metro\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"He gente 35 años en el ha y reconozco que el ...   \n",
       "1       \"interesantes con muchos bares localización\"   \n",
       "2                                                \"…\"   \n",
       "3                                \"rica Muy comida..\"   \n",
       "4                               \"del.metro Estación\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.986286                                   1.0   \n",
       "1                             0.991607                                   1.0   \n",
       "2                             1.000000                                   0.0   \n",
       "3                             0.989455                                   1.0   \n",
       "4                             0.988279                                   1.0   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"He gente 35 años en el ha y reconozco que el ...             0.986286   \n",
       "1       \"interesantes con muchos bares localización\"             0.991607   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                                \"Muy comida.. rica\"             0.980956   \n",
       "4                               \"del.metro Estación\"             0.988279   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0                 1.0  \"barrio vivido 35 años en el He y reconozco qu...   \n",
       "1                 1.0       \"bares con muchos localización interesantes\"   \n",
       "2                 0.0                                                \"…\"   \n",
       "3                 1.0                                \"rica Muy comida..\"   \n",
       "4                 1.0                               \"del.metro Estación\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.976794                 1.0   \n",
       "1             0.985325                 1.0   \n",
       "2             1.000000                 0.0   \n",
       "3             0.989455                 1.0   \n",
       "4             0.988279                 1.0   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"He zonas mejoró años en el barrio y reconozco...             0.970291   \n",
       "1       \"interesantes con muchos bares localización\"             0.991607   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                                \"comida.. rica Muy\"             0.964634   \n",
       "4                               \"del.metro Estación\"             0.988279   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0                 1.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 1.0  \n",
       "4                 1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoInvalidDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5a87f-6a1c-4e4a-9033-bbe8ea9b47b4",
   "metadata": {},
   "source": [
    "En este caso, la similitud semántica varía ligeramente, pero la similitud léxica permanece intacta, ya que no se introducen nuevas palabras ni se eliminan palabras existentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c96e2-13e1-4b78-8f33-066e78ae243b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Eliminación aleatoria\n",
    "Este método consiste en eliminar una palabra elegida aleatoriamente en el texto que no sea una palabra vacía."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a7041-ff2d-4015-9606-e10cf37a2b9e",
   "metadata": {},
   "source": [
    "Función que escoge una palabra no vacía de un texto y la elimina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cc15602-0bde-4f58-b094-0ee841eb59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteWord(text):\n",
    "    #Remove the quotation marks\n",
    "    text = removeQuotes(text)\n",
    "\n",
    "    #Get the list of words of the text\n",
    "    wordsList = text.split()\n",
    "\n",
    "    #Remove the spanish stop words from the text\n",
    "    withoutStopWordsTextList = revomeSpanishStopWords(text).split()\n",
    "    \n",
    "    # Calculate and performs the number of deletions based on the line's content\n",
    "    for i in range(calculateModifications(text)):\n",
    "        # Check if there are more than one word to delete from\n",
    "        if len(withoutStopWordsTextList) > 1:\n",
    "            # Generate a random index to select a word for deletion\n",
    "            pos = random.randint(0, len(withoutStopWordsTextList) - 1)\n",
    "    \n",
    "            #Update the index to the original list (with stop words)\n",
    "            indx = wordsList.index(withoutStopWordsTextList[pos])\n",
    "    \n",
    "            #Remove the chosen word\n",
    "            wordsList.pop(indx)\n",
    "            withoutStopWordsTextList.pop(pos)\n",
    "            \n",
    "    # Join the remaining words into a string, add quotes, and return the result\n",
    "    return addQuotes(' '.join(wordsList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b8a6f-7e52-4a83-9c36-7c7587fa4256",
   "metadata": {},
   "source": [
    "Función que realiza la eliminación aleatoria a todos los elementos de una lista de textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238fcd47-7d97-4703-baef-3c58b69afbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomDeletion(textList, targetPath):\n",
    "    #Open the file\n",
    "    targetFile = open(targetPath, \"w\", encoding = 'utf-8')\n",
    "    \n",
    "    newList = []\n",
    "    for text in textList:\n",
    "        newText = deleteWord(text)\n",
    "        newList.append(newText)\n",
    "        targetFile.write(newText + \"\\n\")\n",
    "\n",
    "    #Close the file\n",
    "    targetFile.close()\n",
    "    \n",
    "    return newList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a1beca-d375-423f-b73b-55850e5ea8a5",
   "metadata": {},
   "source": [
    "Se va a realizar este proceso tres veces para generar más textos distintos de los que se posteriormente se elegirán los mejores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dccc3e6-605f-42ff-9876-4429ec89c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the original data\n",
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) \n",
    "\n",
    "#Apply the synonym replacement 3 times to both datasets\n",
    "for i in range(3):\n",
    "    validPath = f\"6. Random Deletion/1. All Augmented Data/validRandomDeletionReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"6. Random Deletion/1. All Augmented Data/invalidRandomDeletionReviews{i + 1}.txt\"\n",
    "\n",
    "    \n",
    "    randomDeletion(validOriginal, validPath)\n",
    "    randomDeletion(invalidOriginal, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1953ed-beb3-4e83-9692-20666eff56cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Análisis de la eliminación aleatoria y selección de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c678ea0-134d-4a5f-9d3c-1ca2e388f834",
   "metadata": {},
   "source": [
    "Importar los datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e83b81d-4fd4-4a00-abb2-e4bc9d701ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25cb8f-2ddf-48be-9107-a7d05fba9692",
   "metadata": {},
   "source": [
    "Importar los datasets generados en la eliminacion aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105ad61d-4adf-474c-8549-ff80b99ca0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the data \n",
    "validRandomDeletionList = []\n",
    "invalidRandomDeletionList = []\n",
    "for i in range(3):\n",
    "    validPath = f\"6. Random Deletion/1. All Augmented Data/validRandomDeletionReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"6. Random Deletion/1. All Augmented Data/invalidRandomDeletionReviews{i + 1}.txt\"\n",
    "\n",
    "    validRandomDeletionList.append(importFromTxtToList(validPath))\n",
    "    invalidRandomDeletionList.append(importFromTxtToList(invalidPath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cbbf28-4bb7-42e0-abd1-6eddf6523b81",
   "metadata": {},
   "source": [
    "Realizar el análisis y la selección de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d4c4bfc-0338-45d3-b01e-1d78aab627e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validWithOriginalPath = '6. Random Deletion/2. Augmented Data/ ValidRandomDeletionWithOriginal.csv'\n",
    "validAugmentedPath = '6. Random Deletion/2. Augmented Data/ValidRandomDeletionData.txt'\n",
    "invalidWithOriginalPath = '6. Random Deletion/2. Augmented Data/InvalidRandomDeletionWithOriginal.csv'\n",
    "invalidAugmentedPath = '6. Random Deletion/2. Augmented Data/InvalidRandomDeletionData.txt'\n",
    "\n",
    "infoValid = processAugmentation(validOriginal, validRandomDeletionList, validWithOriginalPath, validAugmentedPath)\n",
    "infoValidDF = pd.DataFrame(infoValid)\n",
    "infoInvalid = processAugmentation(invalidOriginal, invalidRandomDeletionList, invalidWithOriginalPath, invalidAugmentedPath)\n",
    "infoInvalidDF = pd.DataFrame(infoInvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61a6547c-38b4-4111-b890-1a9223d409e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>0.976980</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>0.945306</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>0.976980</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>\"Tiene fácil acceso para las con movilidad una...</td>\n",
       "      <td>0.951568</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>\"que hayan mejorais\"</td>\n",
       "      <td>0.915591</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"que hayan mejorais\"</td>\n",
       "      <td>0.915591</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"Espero que mejorais\"</td>\n",
       "      <td>0.900617</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"que hayan mejorais\"</td>\n",
       "      <td>0.915591</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>0.989588</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>0.989588</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>\"La estación es antigua, aparte de una sola sa...</td>\n",
       "      <td>0.987141</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>\"La estación es antigua, aparte de una sola sa...</td>\n",
       "      <td>0.944223</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>\"comodo\"</td>\n",
       "      <td>0.800290</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"Bonito\"</td>\n",
       "      <td>0.791561</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"comodo\"</td>\n",
       "      <td>0.800290</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"Bonito\"</td>\n",
       "      <td>0.791561</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                        \"Espero que hayan mejorais\"   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                             \"Bien\"   \n",
       "4                                    \"Bonito comodo\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                               \"que hayan mejorais\"   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                             \"Bien\"   \n",
       "4                                           \"comodo\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.976980                              0.866667   \n",
       "1                             0.915591                              0.666667   \n",
       "2                             0.989588                              0.863636   \n",
       "3                             1.000000                              1.000000   \n",
       "4                             0.800290                              0.500000   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...             0.945306   \n",
       "1                               \"que hayan mejorais\"             0.915591   \n",
       "2  \"La estación es antigua, aparte de tener una s...             0.989588   \n",
       "3                                             \"Bien\"             1.000000   \n",
       "4                                           \"Bonito\"             0.791561   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0            0.866667  \"Tiene fácil acceso para las personas con movi...   \n",
       "1            0.666667                              \"Espero que mejorais\"   \n",
       "2            0.863636  \"La estación es antigua, aparte de una sola sa...   \n",
       "3            1.000000                                             \"Bien\"   \n",
       "4            0.500000                                           \"comodo\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.976980            0.866667   \n",
       "1             0.900617            0.666667   \n",
       "2             0.987141            0.863636   \n",
       "3             1.000000            1.000000   \n",
       "4             0.800290            0.500000   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"Tiene fácil acceso para las con movilidad una...             0.951568   \n",
       "1                               \"que hayan mejorais\"             0.915591   \n",
       "2  \"La estación es antigua, aparte de una sola sa...             0.944223   \n",
       "3                                             \"Bien\"             1.000000   \n",
       "4                                           \"Bonito\"             0.791561   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0            0.866667  \n",
       "1            0.666667  \n",
       "2            0.909091  \n",
       "3            1.000000  \n",
       "4            0.500000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoValidDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bef9b4fa-a0b8-4eb6-a03d-24d9ece921d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>\"He 35 años en el barrio y que el metro nos di...</td>\n",
       "      <td>0.955221</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>\"He vivido 35 años en el y reconozco que el me...</td>\n",
       "      <td>0.966433</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>0.948992</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>\"He 35 años en el barrio y que el metro nos di...</td>\n",
       "      <td>0.955221</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>\"localización con muchos interesantes\"</td>\n",
       "      <td>0.846651</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"localización con muchos interesantes\"</td>\n",
       "      <td>0.846651</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"con muchos bares interesantes\"</td>\n",
       "      <td>0.734324</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"con muchos bares interesantes\"</td>\n",
       "      <td>0.734324</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"…\"</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>\"Muy comida..\"</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"Muy comida..\"</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"Muy comida..\"</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"Muy comida..\"</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>\"del.metro\"</td>\n",
       "      <td>0.768227</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"Estación\"</td>\n",
       "      <td>0.710799</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"Estación\"</td>\n",
       "      <td>0.710799</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"del.metro\"</td>\n",
       "      <td>0.768227</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1       \"localización con muchos bares interesantes\"   \n",
       "2                                                \"…\"   \n",
       "3                                \"Muy rica comida..\"   \n",
       "4                               \"Estación del.metro\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"He 35 años en el barrio y que el metro nos di...   \n",
       "1             \"localización con muchos interesantes\"   \n",
       "2                                                \"…\"   \n",
       "3                                     \"Muy comida..\"   \n",
       "4                                        \"del.metro\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.955221                              0.818182   \n",
       "1                             0.846651                              0.666667   \n",
       "2                             1.000000                              0.000000   \n",
       "3                             0.739944                              0.666667   \n",
       "4                             0.768227                              0.500000   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"He vivido 35 años en el y reconozco que el me...             0.966433   \n",
       "1             \"localización con muchos interesantes\"             0.846651   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                                     \"Muy comida..\"             0.739944   \n",
       "4                                         \"Estación\"             0.710799   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0            0.863636  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1            0.666667                    \"con muchos bares interesantes\"   \n",
       "2            0.000000                                                \"…\"   \n",
       "3            0.666667                                     \"Muy comida..\"   \n",
       "4            0.500000                                         \"Estación\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.948992            0.863636   \n",
       "1             0.734324            0.666667   \n",
       "2             1.000000            0.000000   \n",
       "3             0.739944            0.666667   \n",
       "4             0.710799            0.500000   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"He 35 años en el barrio y que el metro nos di...             0.955221   \n",
       "1                    \"con muchos bares interesantes\"             0.734324   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                                     \"Muy comida..\"             0.739944   \n",
       "4                                        \"del.metro\"             0.768227   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0            0.818182  \n",
       "1            0.666667  \n",
       "2            0.000000  \n",
       "3            0.666667  \n",
       "4            0.500000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoInvalidDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc57ade-e5d1-434b-bfa5-4c9e3479e4a4",
   "metadata": {},
   "source": [
    "Éste método es el que más variación genera de los anteriores tres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374395c-4c76-4e99-8dbe-38c9086eb863",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Combinación de reemplazo por sinónimos, inserción, intercambio y eliminacion \n",
    "Para intentar que haya la mayor variación posibles, manteniendo la semántica de los textos, se van a combinar los cuatro anteriores métodos para evitar un posible overfiting cuando se entrene al modelo con estos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6297a59-2139-4aa2-8f9c-229fd9c2cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performs all EDA transformations\n",
    "def mixedEDAMethods(textList, prob, targetFolder, fileName, numVersion):\n",
    "    targetPath = targetFolder + \"/\" + fileName + str(numVersion) + \".txt\"\n",
    "    \n",
    "    newList = synonymReplacement(textList, prob, targetFolder + \"/1. Intermidiate Augmentation/\" + fileName + str(numVersion) + \"Synonym.txt\")\n",
    "    newList = randomInsertion(newList, targetFolder + \"/1. Intermidiate Augmentation/\" + fileName + str(numVersion) + \"Insertion.txt\")\n",
    "    newList = randomSwap(newList, targetFolder + \"/1. Intermidiate Augmentation/\" + fileName + str(numVersion) + \"Swap.txt\")\n",
    "    newList = randomDeletion(newList, targetPath)\n",
    "    \n",
    "    return newList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67633a2e-b2a9-4415-96d6-eeafd9a72b6b",
   "metadata": {},
   "source": [
    "Se aplica éste método tres veces para generar más datos y despúes escoger los maś convenientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "509fb018-860b-4d1f-9a27-4d4759283fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the original data\n",
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) \n",
    "\n",
    "#Apply the synonym replacement 3 times to both datasets\n",
    "targetFolder = \"7. Mixed EDA/1. All Augmented Data\"\n",
    "for i in range(3):\n",
    "    prob = 0.25 + 2 * i / 10\n",
    "    \n",
    "    mixedEDAMethods(validOriginal, prob, targetFolder, \"validMixedEDAReviews\", i + 1)\n",
    "    mixedEDAMethods(invalidOriginal, prob, targetFolder, \"invalidMixedEDAReviews\", i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c205ef54-5734-4365-99f6-8a1879b19dd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Análisis de la combinación de los métodos y selección de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb262dc-d4a3-4cc1-8969-671fc3a0a435",
   "metadata": {},
   "source": [
    "Importar los datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a447a13-7633-4141-8a99-7c031ba5b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29772b11-5391-48f4-81ce-15a1cecb8d5e",
   "metadata": {},
   "source": [
    "Importar los datasets generados en la eliminacion aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0b18a26-da82-429f-b193-55dcc6d28e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the data \n",
    "validMixedEDAList = []\n",
    "invalidMixedEDAList = []\n",
    "for i in range(3):\n",
    "    validPath = f\"7. Mixed EDA/1. All Augmented Data/validMixedEDAReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"7. Mixed EDA/1. All Augmented Data/invalidMixedEDAReviews{i + 1}.txt\"\n",
    "\n",
    "    validMixedEDAList.append(importFromTxtToList(validPath))\n",
    "    invalidMixedEDAList.append(importFromTxtToList(invalidPath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ce5c1-846c-48d4-94ff-4744398c2ca7",
   "metadata": {},
   "source": [
    "Realizar el análisis y la selección de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87f2c572-71fa-4625-aeba-acf8323aae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validWithOriginalPath = '7. Mixed EDA/2. Augmented Data/ ValidMixedEDAWithOriginal.csv'\n",
    "validAugmentedPath = '7. Mixed EDA/2. Augmented Data/ValidMixedEDAData.txt'\n",
    "invalidWithOriginalPath = '7. Mixed EDA/2. Augmented Data/InvalidMixedEDAWithOriginal.csv'\n",
    "invalidAugmentedPath = '7. Mixed EDA/2. Augmented Data/InvalidMixedEDAData.txt'\n",
    "\n",
    "infoValid = processAugmentation(validOriginal, validMixedEDAList, validWithOriginalPath, validAugmentedPath)\n",
    "infoValidDF = pd.DataFrame(infoValid)\n",
    "infoInvalid = processAugmentation(invalidOriginal, invalidMixedEDAList, invalidWithOriginalPath, invalidAugmentedPath)\n",
    "infoInvalidDF = pd.DataFrame(infoInvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c41b7b7-8667-4524-84b0-a45cc710d913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>\"Tiene fácil movilidad para las salida pueblo ...</td>\n",
       "      <td>0.909179</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>\"tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>0.958459</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>\"Tiene fácil movilidad para las salida pueblo ...</td>\n",
       "      <td>0.909179</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>\"Tiene del entrada para fácil las personas con...</td>\n",
       "      <td>0.849175</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>\"espero \"Espero que mejorais\"\"</td>\n",
       "      <td>0.858184</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"mejorais que hayan Espero\"</td>\n",
       "      <td>0.991634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"espero \"Espero que mejorais\"\"</td>\n",
       "      <td>0.858184</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"que Espero hayan mejorais\"</td>\n",
       "      <td>0.994041</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>\"La (que antigua, a un lado de dar a subterran...</td>\n",
       "      <td>0.788468</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>\"\"La estación sola pertenece aparte de ademas ...</td>\n",
       "      <td>0.858311</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>\"\"La estación metro\" pueblo aparte de tener un...</td>\n",
       "      <td>0.878832</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>\"La (que antigua, a un lado de dar a subterran...</td>\n",
       "      <td>0.788468</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>\"bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"bien\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"\"Bien\"\"</td>\n",
       "      <td>0.963228</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>\"comodo comodo\"\"</td>\n",
       "      <td>0.803378</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>\"\"Bonito comodo\"\"</td>\n",
       "      <td>0.986783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"\"Bonito comodo\"</td>\n",
       "      <td>0.991887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"comodo comodo\"\"</td>\n",
       "      <td>0.803378</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                        \"Espero que hayan mejorais\"   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                             \"Bien\"   \n",
       "4                                    \"Bonito comodo\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"Tiene fácil movilidad para las salida pueblo ...   \n",
       "1                     \"espero \"Espero que mejorais\"\"   \n",
       "2  \"La (que antigua, a un lado de dar a subterran...   \n",
       "3                                             \"bien\"   \n",
       "4                                   \"comodo comodo\"\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.909179                              0.705882   \n",
       "1                             0.858184                              0.666667   \n",
       "2                             0.788468                              0.483871   \n",
       "3                             1.000000                              1.000000   \n",
       "4                             0.803378                              0.500000   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"tiene fácil acceso para las personas con movi...             0.958459   \n",
       "1                        \"mejorais que hayan Espero\"             0.991634   \n",
       "2  \"\"La estación sola pertenece aparte de ademas ...             0.858311   \n",
       "3                                             \"bien\"             1.000000   \n",
       "4                                  \"\"Bonito comodo\"\"             0.986783   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0            0.875000  \"Tiene fácil movilidad para las salida pueblo ...   \n",
       "1            1.000000                     \"espero \"Espero que mejorais\"\"   \n",
       "2            0.954545  \"\"La estación metro\" pueblo aparte de tener un...   \n",
       "3            1.000000                                             \"bien\"   \n",
       "4            1.000000                                   \"\"Bonito comodo\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.909179            0.705882   \n",
       "1             0.858184            0.666667   \n",
       "2             0.878832            0.760000   \n",
       "3             1.000000            1.000000   \n",
       "4             0.991887            1.000000   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"Tiene del entrada para fácil las personas con...             0.849175   \n",
       "1                        \"que Espero hayan mejorais\"             0.994041   \n",
       "2  \"La (que antigua, a un lado de dar a subterran...             0.788468   \n",
       "3                                           \"\"Bien\"\"             0.963228   \n",
       "4                                   \"comodo comodo\"\"             0.803378   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0            0.647059  \n",
       "1            1.000000  \n",
       "2            0.483871  \n",
       "3            1.000000  \n",
       "4            0.500000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoValidDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9c4a348-7e0d-4890-b257-86664bae6c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>\"barrio desaparecido. 35 mucho tiempo en el pr...</td>\n",
       "      <td>0.897766</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>\"He vivido 35 años en el barrio desaparecido y...</td>\n",
       "      <td>0.919991</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>\"tren 35 tiempo zonas en el mejoró y reconozco...</td>\n",
       "      <td>0.851737</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>\"barrio desaparecido. 35 mucho tiempo en el pr...</td>\n",
       "      <td>0.897766</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>\"localizacion bares con muchos \"localización\"</td>\n",
       "      <td>0.917731</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"interesantes con muchos localización interesa...</td>\n",
       "      <td>0.798462</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"bares con muchos localización interesantes\"</td>\n",
       "      <td>0.985325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"localizacion bares con muchos \"localización\"</td>\n",
       "      <td>0.917731</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"…\"</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"…\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>\"rica rica Muy\"</td>\n",
       "      <td>0.872533</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"Muy comida.. rica\"</td>\n",
       "      <td>0.980956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"rica rica Muy\"</td>\n",
       "      <td>0.872533</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>\"\"Muy comida..\" rica\"</td>\n",
       "      <td>0.942068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"del.metro Estación\"</td>\n",
       "      <td>0.988279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1       \"localización con muchos bares interesantes\"   \n",
       "2                                                \"…\"   \n",
       "3                                \"Muy rica comida..\"   \n",
       "4                               \"Estación del.metro\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"barrio desaparecido. 35 mucho tiempo en el pr...   \n",
       "1      \"localizacion bares con muchos \"localización\"   \n",
       "2                                                \"…\"   \n",
       "3                                    \"rica rica Muy\"   \n",
       "4                               \"Estación del.metro\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.897766                              0.692308   \n",
       "1                             0.917731                              0.666667   \n",
       "2                             1.000000                              0.000000   \n",
       "3                             0.872533                              0.666667   \n",
       "4                             1.000000                              1.000000   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"He vivido 35 años en el barrio desaparecido y...             0.919991   \n",
       "1  \"interesantes con muchos localización interesa...             0.798462   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                                \"Muy comida.. rica\"             0.980956   \n",
       "4                               \"Estación del.metro\"             1.000000   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0            0.720000  \"tren 35 tiempo zonas en el mejoró y reconozco...   \n",
       "1            0.666667       \"bares con muchos localización interesantes\"   \n",
       "2            0.000000                                                \"…\"   \n",
       "3            1.000000                                    \"rica rica Muy\"   \n",
       "4            1.000000                               \"del.metro Estación\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.851737            0.720000   \n",
       "1             0.985325            1.000000   \n",
       "2             1.000000            0.000000   \n",
       "3             0.872533            0.666667   \n",
       "4             0.988279            1.000000   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"barrio desaparecido. 35 mucho tiempo en el pr...             0.897766   \n",
       "1      \"localizacion bares con muchos \"localización\"             0.917731   \n",
       "2                                                \"…\"             1.000000   \n",
       "3                              \"\"Muy comida..\" rica\"             0.942068   \n",
       "4                               \"Estación del.metro\"             1.000000   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0            0.692308  \n",
       "1            0.666667  \n",
       "2            0.000000  \n",
       "3            1.000000  \n",
       "4            1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoInvalidDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b77fc-3e6b-4243-9bec-2b80e43eb8ff",
   "metadata": {},
   "source": [
    "Como se puede ver, los resultados generados son mucho más prometedores ya que genrean más variabilidad léxica pero mantienen bastante alta la similitud semántica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60075ddb-5bec-430c-b98a-0f47115569e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Albumentation\n",
    "Consiste en cambiar el orden de las frases de un texto y eliminar las repetidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88180db0-8a89-48d9-97a2-00bfde609281",
   "metadata": {},
   "source": [
    "Función que obtiene las frases de un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9b1bae7-1671-484f-8e60-b505c0880ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUniqueSentences(text):\n",
    "    # Remove quotes from the input line to ensure clean processing\n",
    "    newText = removeQuotes(text)\n",
    "    # Split the cleaned line into sentences using '.' as the delimiter and create a set comprehension to ensure unique sentences\n",
    "    sentencesSet = {sentence.strip() + \".\" for sentence in newText.split('.') if sentence.strip()}\n",
    "    # Return the set of unique sentences\n",
    "    \n",
    "    return sentencesSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cebdc-87bf-442c-b1bd-4596fd74270c",
   "metadata": {},
   "source": [
    "Función que cambia el orden de las frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da81cdc8-9f8f-4417-be3e-93c1261f6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixSentences(sentencesSet):\n",
    "    # Convert the input set of sentences into a list for shuffling\n",
    "    newList = list(sentencesSet)\n",
    "    # Shuffle the list in place to randomize the order of sentences\n",
    "    random.shuffle(newList)\n",
    "    # Join the shuffled sentences into a single string, adding quotes around it\n",
    "    return addQuotes(' '.join(newList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9594a3-8ca5-4452-bf86-471fc4f7b025",
   "metadata": {},
   "source": [
    "Función que realiza la \"albumentation\" a todos lo elementos de una lista de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9d20a6f-2aa0-49d5-a4b7-7dbc9f3437af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP albumentation method\n",
    "def albumentation(textList, targetPath):\n",
    "    #Open the target file\n",
    "    targetFile = open(targetPath, \"w\", encoding = 'utf-8')\n",
    "    \n",
    "    newList = []\n",
    "    for text in textList:\n",
    "        newText = mixSentences(getUniqueSentences(text))\n",
    "        newList.append(newText)\n",
    "        targetFile.write(newText + \"\\n\")\n",
    "\n",
    "    #Close the file\n",
    "    targetFile.close()\n",
    "    \n",
    "    return newList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c296b1c-3dab-4ff2-8650-690c104afcc4",
   "metadata": {},
   "source": [
    "Se va a realizar este proceso tres veces para tener más datos y luego poder escoger los mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fa6a53d-1d1b-414a-ae74-4f9237e996db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the original data\n",
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) \n",
    "\n",
    "#Apply the synonym replacement 3 times to both datasets\n",
    "for i in range(3):\n",
    "    validPath = f\"8. Albumentation/1. All Augmented Data/validAlbumentationReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"8. Albumentation/1. All Augmented Data/invalidAlbumentationReviews{i + 1}.txt\"\n",
    "\n",
    "    \n",
    "    albumentation(validOriginal, validPath)\n",
    "    albumentation(invalidOriginal, invalidPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d2cb8-f762-4b5b-881b-f96bd94cbfc4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Análisis del \"albumentation\" y selección de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223603a-a7d8-462b-83bd-10480ea8e5c6",
   "metadata": {},
   "source": [
    "Importar los datos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd004472-183c-48bb-ae0c-eb920d5de75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validOriginal = importFromTxtToList(validOriginalPath)\n",
    "invalidOriginal = importFromTxtToList(invalidOriginalPath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46d406-607c-4aa3-8496-b57415d869a6",
   "metadata": {},
   "source": [
    "Importar los datasets generados en el intercambio aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9891032-8cd6-4362-abef-50c881ef8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the data \n",
    "validAlbumentationList = []\n",
    "invalidAlbumentationList = []\n",
    "for i in range(3):\n",
    "    validPath = f\"8. Albumentation/1. All Augmented Data/validAlbumentationReviews{i + 1}.txt\"\n",
    "    invalidPath = f\"8. Albumentation/1. All Augmented Data/invalidAlbumentationReviews{i + 1}.txt\"\n",
    "\n",
    "    validAlbumentationList.append(importFromTxtToList(validPath))\n",
    "    invalidAlbumentationList.append(importFromTxtToList(invalidPath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc1826-14b4-4c0a-813c-1b81ab7fa041",
   "metadata": {},
   "source": [
    "Realizar el análisis y la selección de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aaa878b-cdf3-41ac-bb11-1d37460139a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validWithOriginalPath = '8. Albumentation/2. Augmented Data/ ValidAlbumentationWithOriginal.csv'\n",
    "validAugmentedPath = '8. Albumentation/2. Augmented Data/ValidAlbumentationData.txt'\n",
    "invalidWithOriginalPath = '8. Albumentation/2. Augmented Data/InvalidAlbumentationWithOriginal.csv'\n",
    "invalidAugmentedPath = '8. Albumentation/2. Augmented Data/InvalidAlbumentationData.txt'\n",
    "\n",
    "infoValid = processAugmentation(validOriginal, validAlbumentationList, validWithOriginalPath, validAugmentedPath)\n",
    "infoValidDF = pd.DataFrame(infoValid)\n",
    "infoInvalid = processAugmentation(invalidOriginal, invalidAlbumentationList, invalidWithOriginalPath, invalidAugmentedPath)\n",
    "infoInvalidDF = pd.DataFrame(infoInvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "718749de-5e1b-4063-83a1-338eadf04305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Tiene fácil acceso para las personas con movi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Espero que hayan mejorais\"</td>\n",
       "      <td>\"Espero que hayan mejorais.\"</td>\n",
       "      <td>0.978180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Espero que hayan mejorais.\"</td>\n",
       "      <td>0.978180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Espero que hayan mejorais.\"</td>\n",
       "      <td>0.978180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Espero que hayan mejorais.\"</td>\n",
       "      <td>0.978180</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Además comunica por un pasillo subterráneo (q...</td>\n",
       "      <td>0.941534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"La estación es antigua, aparte de tener una s...</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Además comunica por un pasillo subterráneo (q...</td>\n",
       "      <td>0.941534</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bien\"</td>\n",
       "      <td>\"Bien.\"</td>\n",
       "      <td>0.909274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Bien.\"</td>\n",
       "      <td>0.909274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Bien.\"</td>\n",
       "      <td>0.909274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Bien.\"</td>\n",
       "      <td>0.909274</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bonito comodo\"</td>\n",
       "      <td>\"Bonito comodo.\"</td>\n",
       "      <td>0.956156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Bonito comodo.\"</td>\n",
       "      <td>0.956156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Bonito comodo.\"</td>\n",
       "      <td>0.956156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Bonito comodo.\"</td>\n",
       "      <td>0.956156</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                        \"Espero que hayan mejorais\"   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                             \"Bien\"   \n",
       "4                                    \"Bonito comodo\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                       \"Espero que hayan mejorais.\"   \n",
       "2  \"La estación es antigua, aparte de tener una s...   \n",
       "3                                            \"Bien.\"   \n",
       "4                                   \"Bonito comodo.\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             1.000000                                   1.0   \n",
       "1                             0.978180                                   1.0   \n",
       "2                             0.998383                                   1.0   \n",
       "3                             0.909274                                   1.0   \n",
       "4                             0.956156                                   1.0   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...             1.000000   \n",
       "1                       \"Espero que hayan mejorais.\"             0.978180   \n",
       "2  \"Además comunica por un pasillo subterráneo (q...             0.941534   \n",
       "3                                            \"Bien.\"             0.909274   \n",
       "4                                   \"Bonito comodo.\"             0.956156   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0                 1.0  \"Tiene fácil acceso para las personas con movi...   \n",
       "1                 1.0                       \"Espero que hayan mejorais.\"   \n",
       "2                 1.0  \"La estación es antigua, aparte de tener una s...   \n",
       "3                 1.0                                            \"Bien.\"   \n",
       "4                 1.0                                   \"Bonito comodo.\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             1.000000                 1.0   \n",
       "1             0.978180                 1.0   \n",
       "2             0.998383                 1.0   \n",
       "3             0.909274                 1.0   \n",
       "4             0.956156                 1.0   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"Tiene fácil acceso para las personas con movi...             1.000000   \n",
       "1                       \"Espero que hayan mejorais.\"             0.978180   \n",
       "2  \"Además comunica por un pasillo subterráneo (q...             0.941534   \n",
       "3                                            \"Bien.\"             0.909274   \n",
       "4                                   \"Bonito comodo.\"             0.956156   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0                 1.0  \n",
       "1                 1.0  \n",
       "2                 1.0  \n",
       "3                 1.0  \n",
       "4                 1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoValidDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f15ddf63-4b1f-4f18-a7c9-eb28c3ae1fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalText</th>\n",
       "      <th>bestAugmentation</th>\n",
       "      <th>bestAugmentedDataSemanticSimilarity</th>\n",
       "      <th>bestAugmentedDataLexicalSimiliratity</th>\n",
       "      <th>augmented1</th>\n",
       "      <th>semanticSimilarity1</th>\n",
       "      <th>lexicalSimilarity1</th>\n",
       "      <th>augmented2</th>\n",
       "      <th>semanticSimilarity2</th>\n",
       "      <th>lexicalSimilarity2</th>\n",
       "      <th>augmented3</th>\n",
       "      <th>semanticSimilarity3</th>\n",
       "      <th>lexicalSimilarity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"Una pena. La gente joven se ha ido a otras zo...</td>\n",
       "      <td>0.966767</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"He vivido 35 años en el barrio y reconozco qu...</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"Desgraciadamente el barrio que conocí práctic...</td>\n",
       "      <td>0.959858</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"localización con muchos bares interesantes\"</td>\n",
       "      <td>\"localización con muchos bares interesantes.\"</td>\n",
       "      <td>0.972995</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"localización con muchos bares interesantes.\"</td>\n",
       "      <td>0.972995</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"localización con muchos bares interesantes.\"</td>\n",
       "      <td>0.972995</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"localización con muchos bares interesantes.\"</td>\n",
       "      <td>0.972995</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"…\"</td>\n",
       "      <td>\"….\"</td>\n",
       "      <td>0.911401</td>\n",
       "      <td>0.00</td>\n",
       "      <td>\"….\"</td>\n",
       "      <td>0.911401</td>\n",
       "      <td>0.00</td>\n",
       "      <td>\"….\"</td>\n",
       "      <td>0.911401</td>\n",
       "      <td>0.00</td>\n",
       "      <td>\"….\"</td>\n",
       "      <td>0.911401</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Muy rica comida..\"</td>\n",
       "      <td>\"Muy rica comida.\"</td>\n",
       "      <td>0.995217</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"Muy rica comida.\"</td>\n",
       "      <td>0.995217</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"Muy rica comida.\"</td>\n",
       "      <td>0.995217</td>\n",
       "      <td>1.00</td>\n",
       "      <td>\"Muy rica comida.\"</td>\n",
       "      <td>0.995217</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Estación del.metro\"</td>\n",
       "      <td>\"Estación del. metro.\"</td>\n",
       "      <td>0.987054</td>\n",
       "      <td>0.25</td>\n",
       "      <td>\"Estación del. metro.\"</td>\n",
       "      <td>0.987054</td>\n",
       "      <td>0.25</td>\n",
       "      <td>\"metro. Estación del.\"</td>\n",
       "      <td>0.973336</td>\n",
       "      <td>0.25</td>\n",
       "      <td>\"metro. Estación del.\"</td>\n",
       "      <td>0.973336</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        originalText  \\\n",
       "0  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1       \"localización con muchos bares interesantes\"   \n",
       "2                                                \"…\"   \n",
       "3                                \"Muy rica comida..\"   \n",
       "4                               \"Estación del.metro\"   \n",
       "\n",
       "                                    bestAugmentation  \\\n",
       "0  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1      \"localización con muchos bares interesantes.\"   \n",
       "2                                               \"….\"   \n",
       "3                                 \"Muy rica comida.\"   \n",
       "4                             \"Estación del. metro.\"   \n",
       "\n",
       "   bestAugmentedDataSemanticSimilarity  bestAugmentedDataLexicalSimiliratity  \\\n",
       "0                             0.995105                                  1.00   \n",
       "1                             0.972995                                  1.00   \n",
       "2                             0.911401                                  0.00   \n",
       "3                             0.995217                                  1.00   \n",
       "4                             0.987054                                  0.25   \n",
       "\n",
       "                                          augmented1  semanticSimilarity1  \\\n",
       "0  \"Una pena. La gente joven se ha ido a otras zo...             0.966767   \n",
       "1      \"localización con muchos bares interesantes.\"             0.972995   \n",
       "2                                               \"….\"             0.911401   \n",
       "3                                 \"Muy rica comida.\"             0.995217   \n",
       "4                             \"Estación del. metro.\"             0.987054   \n",
       "\n",
       "   lexicalSimilarity1                                         augmented2  \\\n",
       "0                1.00  \"He vivido 35 años en el barrio y reconozco qu...   \n",
       "1                1.00      \"localización con muchos bares interesantes.\"   \n",
       "2                0.00                                               \"….\"   \n",
       "3                1.00                                 \"Muy rica comida.\"   \n",
       "4                0.25                             \"metro. Estación del.\"   \n",
       "\n",
       "   semanticSimilarity2  lexicalSimilarity2  \\\n",
       "0             0.995105                1.00   \n",
       "1             0.972995                1.00   \n",
       "2             0.911401                0.00   \n",
       "3             0.995217                1.00   \n",
       "4             0.973336                0.25   \n",
       "\n",
       "                                          augmented3  semanticSimilarity3  \\\n",
       "0  \"Desgraciadamente el barrio que conocí práctic...             0.959858   \n",
       "1      \"localización con muchos bares interesantes.\"             0.972995   \n",
       "2                                               \"….\"             0.911401   \n",
       "3                                 \"Muy rica comida.\"             0.995217   \n",
       "4                             \"metro. Estación del.\"             0.973336   \n",
       "\n",
       "   lexicalSimilarity3  \n",
       "0                1.00  \n",
       "1                1.00  \n",
       "2                0.00  \n",
       "3                1.00  \n",
       "4                0.25  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoInvalidDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8662052-876d-407b-9db9-570d9f50d44f",
   "metadata": {},
   "source": [
    "En este caso, la similitud semántica varía ligeramente, pero la similitud léxica permanece intacta, ya que no se introducen nuevas palabras ni se eliminan palabras existentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0435858-3d91-4c26-a0c3-ddd562b2f189",
   "metadata": {},
   "source": [
    "# Aumento de datos con modelos preentrenados\n",
    "Para realizar esta sección del aumento de datos se va a seguir el artículo \"Dara Augmentation Using Pre-trained Transformer Models\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a450b091-5e0a-4175-a700-9ae4ea0ab2ab",
   "metadata": {},
   "source": [
    "## GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7aba1b-546b-4383-a70c-a03230e56bca",
   "metadata": {},
   "source": [
    "### Primer enfoque\n",
    "Se van a hacer el refinamiento del modelo preentrenado GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f687342-de46-4cf0-a719-fb094e94904e",
   "metadata": {},
   "source": [
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa920e8-86e7-4a00-9266-a2e17ebcf3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d41fbe0-d3bc-4334-a2bb-e4ada78603f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFromTxtToDictList(source):\n",
    "    dictList = []\n",
    "    with open(source, 'r', encoding=\"utf-8\") as file:\n",
    "        for line in file: \n",
    "            dictList.append({\"text\" : line.strip()})\n",
    "            \n",
    "    return dictList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9778118-9f5f-418b-bd3c-45aa40085eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/AllUnlabeledReviews.txt\"\n",
    "\n",
    "#Each row is a dictionary with the key text and the text as the value\n",
    "dataDictList = importFromTxtToDictList(path)\n",
    "#The list of dictionaries is converted to a dataset\n",
    "dataset = Dataset.from_list(dataDictList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef673400-22ed-4f0b-86cd-70d0aa220f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 3234\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921326a1-b188-4c52-bc7c-aa6f603676c5",
   "metadata": {},
   "source": [
    "### Tokenización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd4930d-c890-4abb-b04f-8d97f60398b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeFunction(examples, tokenizer):\n",
    "    return tokenizer(examples[\"text\"], truncation = True, padding = \"max_length\", max_length = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f256f-9cab-40a8-8ba4-112e66c23357",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e38b4097-bec4-42b0-b6cc-d110e1200f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(savingPath, modelName, version, tokenizeFunction, dataset, fineTuneAllLayers = True, trainEpochs = 3, lr = 5e-5, freezePctg = 0.8):\n",
    "    #Download the pretrained model and the tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(modelName)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "    \n",
    "    #Check if the tokenizer has a padding toke\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "    tokenizedDataset = dataset.map(lambda x: tokenizeFunction(x, tokenizer), batched = True)\n",
    "\n",
    "    #If necessary freeze the layers that do not have to be trained\n",
    "    if not fineTuneAllLayers:\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'transformer.h.' in name:  # GPT2 has blocks called 'transformer.h.X'\n",
    "                layer_num = int(name.split('.')[2])\n",
    "                if layer_num < model.config.n_layer * freezePctg:  #Freeze 80 % of the layers\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = savingPath + \"/\" + modelName.replace(\"/\", \"%\"),\n",
    "        overwrite_output_dir = True,\n",
    "        num_train_epochs = trainEpochs,\n",
    "        per_device_train_batch_size = 8,\n",
    "        logging_steps = 10,\n",
    "        eval_strategy = \"no\",\n",
    "        save_strategy = \"no\",\n",
    "        fp16 = True,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        weight_decay=0.01,                \n",
    "        warmup_steps=500,  \n",
    "        learning_rate = lr,\n",
    "        logging_dir = savingPath + \"/\" + modelName.replace(\"/\", \"%\"),\n",
    "    )\n",
    "\n",
    "    dataCollator = DataCollatorForLanguageModeling(\n",
    "        tokenizer = tokenizer,\n",
    "        mlm = False,  # Is not a mask lenguage model\n",
    "    )\n",
    "\n",
    "    #Generates the labels automatically so that the model can predict the next token\n",
    "    trainer = Trainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = tokenizedDataset,\n",
    "        data_collator = dataCollator,\n",
    "    )\n",
    "\n",
    "    #Train the model\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train()\n",
    "\n",
    "    #Save the model\n",
    "    tokenizer.save_pretrained(savingPath + \"/\" + modelName.replace(\"/\", \"%\") + \"v\" + str(version))\n",
    "    model.save_pretrained(savingPath + \"/\" + modelName.replace(\"/\", \"%\") + \"v\" + str(version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c697657c-2bf4-4de1-aa4a-4d95f8008d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "Map: 100%|██████████| 3234/3234 [00:00<00:00, 7890.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight is being updated\n",
      "transformer.wpe.weight is being updated\n",
      "transformer.h.0.ln_1.weight is frozen\n",
      "transformer.h.0.ln_1.bias is frozen\n",
      "transformer.h.0.attn.c_attn.weight is frozen\n",
      "transformer.h.0.attn.c_attn.bias is frozen\n",
      "transformer.h.0.attn.c_proj.weight is frozen\n",
      "transformer.h.0.attn.c_proj.bias is frozen\n",
      "transformer.h.0.ln_2.weight is frozen\n",
      "transformer.h.0.ln_2.bias is frozen\n",
      "transformer.h.0.mlp.c_fc.weight is frozen\n",
      "transformer.h.0.mlp.c_fc.bias is frozen\n",
      "transformer.h.0.mlp.c_proj.weight is frozen\n",
      "transformer.h.0.mlp.c_proj.bias is frozen\n",
      "transformer.h.1.ln_1.weight is frozen\n",
      "transformer.h.1.ln_1.bias is frozen\n",
      "transformer.h.1.attn.c_attn.weight is frozen\n",
      "transformer.h.1.attn.c_attn.bias is frozen\n",
      "transformer.h.1.attn.c_proj.weight is frozen\n",
      "transformer.h.1.attn.c_proj.bias is frozen\n",
      "transformer.h.1.ln_2.weight is frozen\n",
      "transformer.h.1.ln_2.bias is frozen\n",
      "transformer.h.1.mlp.c_fc.weight is frozen\n",
      "transformer.h.1.mlp.c_fc.bias is frozen\n",
      "transformer.h.1.mlp.c_proj.weight is frozen\n",
      "transformer.h.1.mlp.c_proj.bias is frozen\n",
      "transformer.h.2.ln_1.weight is frozen\n",
      "transformer.h.2.ln_1.bias is frozen\n",
      "transformer.h.2.attn.c_attn.weight is frozen\n",
      "transformer.h.2.attn.c_attn.bias is frozen\n",
      "transformer.h.2.attn.c_proj.weight is frozen\n",
      "transformer.h.2.attn.c_proj.bias is frozen\n",
      "transformer.h.2.ln_2.weight is frozen\n",
      "transformer.h.2.ln_2.bias is frozen\n",
      "transformer.h.2.mlp.c_fc.weight is frozen\n",
      "transformer.h.2.mlp.c_fc.bias is frozen\n",
      "transformer.h.2.mlp.c_proj.weight is frozen\n",
      "transformer.h.2.mlp.c_proj.bias is frozen\n",
      "transformer.h.3.ln_1.weight is frozen\n",
      "transformer.h.3.ln_1.bias is frozen\n",
      "transformer.h.3.attn.c_attn.weight is frozen\n",
      "transformer.h.3.attn.c_attn.bias is frozen\n",
      "transformer.h.3.attn.c_proj.weight is frozen\n",
      "transformer.h.3.attn.c_proj.bias is frozen\n",
      "transformer.h.3.ln_2.weight is frozen\n",
      "transformer.h.3.ln_2.bias is frozen\n",
      "transformer.h.3.mlp.c_fc.weight is frozen\n",
      "transformer.h.3.mlp.c_fc.bias is frozen\n",
      "transformer.h.3.mlp.c_proj.weight is frozen\n",
      "transformer.h.3.mlp.c_proj.bias is frozen\n",
      "transformer.h.4.ln_1.weight is frozen\n",
      "transformer.h.4.ln_1.bias is frozen\n",
      "transformer.h.4.attn.c_attn.weight is frozen\n",
      "transformer.h.4.attn.c_attn.bias is frozen\n",
      "transformer.h.4.attn.c_proj.weight is frozen\n",
      "transformer.h.4.attn.c_proj.bias is frozen\n",
      "transformer.h.4.ln_2.weight is frozen\n",
      "transformer.h.4.ln_2.bias is frozen\n",
      "transformer.h.4.mlp.c_fc.weight is frozen\n",
      "transformer.h.4.mlp.c_fc.bias is frozen\n",
      "transformer.h.4.mlp.c_proj.weight is frozen\n",
      "transformer.h.4.mlp.c_proj.bias is frozen\n",
      "transformer.h.5.ln_1.weight is frozen\n",
      "transformer.h.5.ln_1.bias is frozen\n",
      "transformer.h.5.attn.c_attn.weight is frozen\n",
      "transformer.h.5.attn.c_attn.bias is frozen\n",
      "transformer.h.5.attn.c_proj.weight is frozen\n",
      "transformer.h.5.attn.c_proj.bias is frozen\n",
      "transformer.h.5.ln_2.weight is frozen\n",
      "transformer.h.5.ln_2.bias is frozen\n",
      "transformer.h.5.mlp.c_fc.weight is frozen\n",
      "transformer.h.5.mlp.c_fc.bias is frozen\n",
      "transformer.h.5.mlp.c_proj.weight is frozen\n",
      "transformer.h.5.mlp.c_proj.bias is frozen\n",
      "transformer.h.6.ln_1.weight is frozen\n",
      "transformer.h.6.ln_1.bias is frozen\n",
      "transformer.h.6.attn.c_attn.weight is frozen\n",
      "transformer.h.6.attn.c_attn.bias is frozen\n",
      "transformer.h.6.attn.c_proj.weight is frozen\n",
      "transformer.h.6.attn.c_proj.bias is frozen\n",
      "transformer.h.6.ln_2.weight is frozen\n",
      "transformer.h.6.ln_2.bias is frozen\n",
      "transformer.h.6.mlp.c_fc.weight is frozen\n",
      "transformer.h.6.mlp.c_fc.bias is frozen\n",
      "transformer.h.6.mlp.c_proj.weight is frozen\n",
      "transformer.h.6.mlp.c_proj.bias is frozen\n",
      "transformer.h.7.ln_1.weight is frozen\n",
      "transformer.h.7.ln_1.bias is frozen\n",
      "transformer.h.7.attn.c_attn.weight is frozen\n",
      "transformer.h.7.attn.c_attn.bias is frozen\n",
      "transformer.h.7.attn.c_proj.weight is frozen\n",
      "transformer.h.7.attn.c_proj.bias is frozen\n",
      "transformer.h.7.ln_2.weight is frozen\n",
      "transformer.h.7.ln_2.bias is frozen\n",
      "transformer.h.7.mlp.c_fc.weight is frozen\n",
      "transformer.h.7.mlp.c_fc.bias is frozen\n",
      "transformer.h.7.mlp.c_proj.weight is frozen\n",
      "transformer.h.7.mlp.c_proj.bias is frozen\n",
      "transformer.h.8.ln_1.weight is frozen\n",
      "transformer.h.8.ln_1.bias is frozen\n",
      "transformer.h.8.attn.c_attn.weight is frozen\n",
      "transformer.h.8.attn.c_attn.bias is frozen\n",
      "transformer.h.8.attn.c_proj.weight is frozen\n",
      "transformer.h.8.attn.c_proj.bias is frozen\n",
      "transformer.h.8.ln_2.weight is frozen\n",
      "transformer.h.8.ln_2.bias is frozen\n",
      "transformer.h.8.mlp.c_fc.weight is frozen\n",
      "transformer.h.8.mlp.c_fc.bias is frozen\n",
      "transformer.h.8.mlp.c_proj.weight is frozen\n",
      "transformer.h.8.mlp.c_proj.bias is frozen\n",
      "transformer.h.9.ln_1.weight is frozen\n",
      "transformer.h.9.ln_1.bias is frozen\n",
      "transformer.h.9.attn.c_attn.weight is frozen\n",
      "transformer.h.9.attn.c_attn.bias is frozen\n",
      "transformer.h.9.attn.c_proj.weight is frozen\n",
      "transformer.h.9.attn.c_proj.bias is frozen\n",
      "transformer.h.9.ln_2.weight is frozen\n",
      "transformer.h.9.ln_2.bias is frozen\n",
      "transformer.h.9.mlp.c_fc.weight is frozen\n",
      "transformer.h.9.mlp.c_fc.bias is frozen\n",
      "transformer.h.9.mlp.c_proj.weight is frozen\n",
      "transformer.h.9.mlp.c_proj.bias is frozen\n",
      "transformer.h.10.ln_1.weight is being updated\n",
      "transformer.h.10.ln_1.bias is being updated\n",
      "transformer.h.10.attn.c_attn.weight is being updated\n",
      "transformer.h.10.attn.c_attn.bias is being updated\n",
      "transformer.h.10.attn.c_proj.weight is being updated\n",
      "transformer.h.10.attn.c_proj.bias is being updated\n",
      "transformer.h.10.ln_2.weight is being updated\n",
      "transformer.h.10.ln_2.bias is being updated\n",
      "transformer.h.10.mlp.c_fc.weight is being updated\n",
      "transformer.h.10.mlp.c_fc.bias is being updated\n",
      "transformer.h.10.mlp.c_proj.weight is being updated\n",
      "transformer.h.10.mlp.c_proj.bias is being updated\n",
      "transformer.h.11.ln_1.weight is being updated\n",
      "transformer.h.11.ln_1.bias is being updated\n",
      "transformer.h.11.attn.c_attn.weight is being updated\n",
      "transformer.h.11.attn.c_attn.bias is being updated\n",
      "transformer.h.11.attn.c_proj.weight is being updated\n",
      "transformer.h.11.attn.c_proj.bias is being updated\n",
      "transformer.h.11.ln_2.weight is being updated\n",
      "transformer.h.11.ln_2.bias is being updated\n",
      "transformer.h.11.mlp.c_fc.weight is being updated\n",
      "transformer.h.11.mlp.c_fc.bias is being updated\n",
      "transformer.h.11.mlp.c_proj.weight is being updated\n",
      "transformer.h.11.mlp.c_proj.bias is being updated\n",
      "transformer.ln_f.weight is being updated\n",
      "transformer.ln_f.bias is being updated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='303' max='303' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [303/303 05:56, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>18.643400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>18.863100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>19.276100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>18.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>18.424400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>19.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>18.869900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>18.996400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>18.348800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>18.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>18.084900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>18.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>17.794400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>18.962900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>18.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>17.565300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>17.965400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>18.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>17.913800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>17.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>17.304500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>17.826600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>17.587300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>17.556800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>16.949100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>16.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>17.239300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>17.258300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>17.082500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>16.501400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "savingPath = \"/home/ibon/Documentos/1. Models\"\n",
    "modelName = \"mrm8488/spanish-gpt2\"\n",
    "trainModel(savingPath, modelName, 2, tokenizeFunction, dataset, fineTuneAllLayers = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faad526-5ec9-48ef-9488-1977d3bebd97",
   "metadata": {},
   "source": [
    "### Generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6250528c-167e-48b1-a3b7-14a3aa5c630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateText(modelPath, text):\n",
    "    #Load the model\n",
    "    model = AutoModelForCausalLM.from_pretrained(modelPath)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(modelPath)\n",
    "\n",
    "    #Check if the tokenizer has a padding token\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    #Tokenize the input text\n",
    "    inputIds = tokenizer.encode(text, return_tensors = \"pt\")\n",
    "\n",
    "    #Generate the text\n",
    "    output = model.generate(inputIds, max_length = len(text), num_return_sequences = 1, \n",
    "                            pad_token_id = tokenizer.pad_token_id, eos_token_id = tokenizer.eos_token_id, \n",
    "                            temperature = 0.7, top_k = 50, top_p = 0.9, repetition_penalty = 2.0,\n",
    "                            no_repeat_ngram_size = 3,)\n",
    "\n",
    "    #Decode the text\n",
    "    generatedText = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return generatedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7accdd75-7e83-40a8-af07-e699046da08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todo bien?- Sí.¿Qué pasa\n"
     ]
    }
   ],
   "source": [
    "modelPath = savingPath + \"/\" + modelName.replace(\"/\", \"%\") + \"v2\"\n",
    "text = \"Todo bien\"\n",
    "\n",
    "generatedText = generateText(modelPath, text)\n",
    "\n",
    "print(generatedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f239ef4-a698-4c32-9472-85eb77085c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e8479c9-3f54-48c5-bb0b-99de1acd25e0",
   "metadata": {},
   "source": [
    "#### Preparación de los datos\n",
    "Siguiendo el artículo, se van a anteponer las etiquetas de las clases a los ejemplos de las clases. Es decir, los datos que se van a proporcionar al modelo tendrán la siguiente forma: etiqueta : texto.\n",
    "\n",
    "Originalmente, las etiquetas del cojunto de datos eran v (valida) y n (no válida). Sin embargo, para proporcionar más contexto semántico al modelo, se van a extender a valida y noValida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4904cf53-fe1a-4148-8192-1eac1dc5fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that generates a list in which each element is: label : text. Where text is a line in the given file.\n",
    "def dataPreparation(dataPath, label):\n",
    "    dataList = []\n",
    "\n",
    "    #Open and store evety line in the file in a list\n",
    "    with open(dataPath, \"r\", encoding = 'utf-8') as dataFile:\n",
    "        for line in dataFile:\n",
    "            dataList.append(label + \" : \" + line.strip())\n",
    "\n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f94355-e1c8-4101-93b0-85eadd692d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "validOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/ValidReviews.txt\"\n",
    "invalidOriginalPath = \"/home/ibon/Documentos/GitHub/TFG/1. Data/4. Labeled Reviews/2. Without Emojis/InvalidReviews.txt\"\n",
    "\n",
    "validReviewsList = dataPreparation(validOriginalPath, \"valida\")\n",
    "invalidReviewsList = dataPreparation(invalidOriginalPath, \"noValida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a73ca5-1bfd-427f-9401-69c32449016d",
   "metadata": {},
   "source": [
    "Se juntan los dos datasets y se mezclan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7442b8b-a8d6-4c39-9560-00790e3c73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = validReviewsList + invalidReviewsList\n",
    "random.shuffle(dataList, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
